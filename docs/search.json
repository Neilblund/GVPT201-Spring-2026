[
  {
    "objectID": "troubleshooting.html",
    "href": "troubleshooting.html",
    "title": "Troubleshooting R",
    "section": "",
    "text": "Encountering errors and unexpected results is an inevitable part of learning any programming language. The teaching staff is here to help, but before you send an email to your TA, its good to do a little troubleshooting to make sure the problem isn‚Äôt something you can solve on your own.\nEvery problem is different, but there are some steps that I generally recommend taking when you encounter a problem in R.",
    "crumbs": [
      "Additional Resources",
      "Troubleshooting R"
    ]
  },
  {
    "objectID": "troubleshooting.html#step-0-take-a-little-break",
    "href": "troubleshooting.html#step-0-take-a-little-break",
    "title": "Troubleshooting R",
    "section": "Step 0: Take a little break",
    "text": "Step 0: Take a little break\nIn my experience, 99% of errors are the result of stuff like misspelling a variable or forgetting to load a package and they‚Äôre completely obvious once you‚Äôve spotted them. There‚Äôs no way around this, it happens to everyone. The only real advice I can offer here is: take a break and relax your brain. Go for a walk. Eat a sandwich. Pet a cat, etc. Then come back with a fresh set of eyes and retrace your steps to see if you can spot something that looks out of place.\nOnce you‚Äôve done this, take a look at the offending output and see if you can get any clues about its origins. When you see messages like: Error in foo() : could not find function \"foo\" or Error: object 'x' not found its often either a misspelling or its the result of a variable or function that hasn‚Äôt been loaded into R yet.\nOther messages are a little harder to parse, but you can often copy-paste the error into a search engine and you‚Äôll find that other people have gotten help for the same issue. R has a big community of users, and so there‚Äôs a good chance that someone else has encountered the same problem you‚Äôre having and has written about how to solve it. Similarly, if you‚Äôre having an issue with a particular function, consult the help file and see if you can find any useful information there.\nWhen this fails, then move on to step 1.",
    "crumbs": [
      "Additional Resources",
      "Troubleshooting R"
    ]
  },
  {
    "objectID": "troubleshooting.html#step-1-clear-the-environment-and-restart-r",
    "href": "troubleshooting.html#step-1-clear-the-environment-and-restart-r",
    "title": "Troubleshooting R",
    "section": "Step 1: Clear the environment and restart R",
    "text": "Step 1: Clear the environment and restart R\nSome errors are caused by unexpected interactions between different libraries or objects in the working environment. In order to rule out issues like this, you want to start with a ‚Äúfresh‚Äù environment with no packages or data loaded.\nTo restart R, you can press Ctrl + Shift + F10, or just close and reopen R-Studio. Then, to clear the environment, just press the little broom üßπ icon in the environment pane, or enter the following command into the console:\n\nrm(list = ls())",
    "crumbs": [
      "Additional Resources",
      "Troubleshooting R"
    ]
  },
  {
    "objectID": "troubleshooting.html#step-2-try-to-replicate-the-issue",
    "href": "troubleshooting.html#step-2-try-to-replicate-the-issue",
    "title": "Troubleshooting R",
    "section": "Step 2: Try to replicate the issue",
    "text": "Step 2: Try to replicate the issue\nNow that you have a fresh R instance, try to replicate your problem. Make a new script and call it something like ‚Äúerror_replication‚Äù and then try to replicate your error message in as few steps as possible. Remember that you‚Äôll need to re-load any packages or data you‚Äôve been using for your analysis first. For GVPT 201, that usually means at least running library(RCPA3) and possibly loading one of the world, nes, gss or states data sets.\nRun through each line of code one step at a time until you encounter the problem. If you want to be absolutely sure that your code can be replicated, repeat step 1 and then press the ‚Äúsource‚Äù button at the top right of the script editor. This will run the entire script in sequence.\nHere‚Äôs an example of a common error that comes from trying to use the max function on a variable that isn‚Äôt numeric. I might have a lot of other code in my original script, but I only need four lines to replicate this error message and you can easily recreate it yourself by copying these same lines:\n\n# Step 1: After restarting Rstudio and clearing the environment...\n# Step 2: I load the required packages ----\nlibrary(RCPA3)\n# and import the \"world\" data set and assign it to a variable\nworld&lt;-RCPA3::world\n\n# Step 3: And then I recreate my error message----\nmax(world$election.violence.post)\n\nError in Summary.factor(structure(c(1L, NA, 1L, NA, 1L, 2L, 1L, 1L, 1L, : 'max' not meaningful for factors\n\n\nIsolating the problem like this can usually make it a lot easier to spot the source of the issue, but if you can replicate the error and you‚Äôre still not sure how to fix it, then its probably time to move on to the next step.",
    "crumbs": [
      "Additional Resources",
      "Troubleshooting R"
    ]
  },
  {
    "objectID": "troubleshooting.html#step-3-send-an-email",
    "href": "troubleshooting.html#step-3-send-an-email",
    "title": "Troubleshooting R",
    "section": "Step 3: Send an Email",
    "text": "Step 3: Send an Email\nIf you‚Äôve tried the previous steps and you still haven‚Äôt resolved your issue, its time to reach out to a classmate, TA, or the instructor. In order to make that process go as smoothly as possible, you want to be sure to pass along sufficient details about your issue so that someone else can help you troubleshoot. So generally this means including:\n\nA description of the problem and what you‚Äôre trying to do\nThe text of the error message (if applicable) or a screenshot of the problematic output\nA script that can replicate your problem in as few steps as possible (see step 2)\n\nHere‚Äôs an example of how that email might look:\n\n\n\n\n\n\n\nTo: MySectionTA@umd.edu\n\n\nFrom: me@umd.edu\n\n\nSubject: GVPT 201: Error when using max\n\n\nHello, I‚Äôm working on the homework and I keep getting an error message when I try to use the max function.\nThe error message is: Error in Summary.factor(c(1L, NA, 1L, NA, 1L, 2L, 1L, 1L, 1L, 2L, NA,:‚Äòmax‚Äô not meaningful for factors\nI‚Äôve attached an Rscript that replicates the error below\nThank you!\n[here, you would want to attach the error replication script from step 2]",
    "crumbs": [
      "Additional Resources",
      "Troubleshooting R"
    ]
  },
  {
    "objectID": "surveys.html",
    "href": "surveys.html",
    "title": "Class surveys",
    "section": "",
    "text": "Documentation and code for the in-class surveys."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Note that this schedule is subject to change. Be sure to check ELMS for the most up-to-date information on due dates.\n\nGVPT 201 Spring 2026 Schedule\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nTextbook\nHomework\nSlides\n\n\n\n\nWeek 1\nJan 26\nConcepts and measurement\nChapter 1\nHomework 1 due Feb 05Survey question due Feb 06\nIntro\n\n\n\nJan 28\n\n\n\nLecture 1\n\n\nWeek 2\nFeb 02\nDescription\nChapter 2\nHomework 2 due Feb 12\nLecture 2\n\n\n\nFeb 04\n\n\n\nLecture 3\n\n\nWeek 3\nFeb 09\nTransforming variables\nChapter 3\nHomework 3 due Feb 19\nLecture 4\n\n\n\nFeb 11\n\n\n\nLecture 5\n\n\nWeek 4\nFeb 16\nExplanations and hypotheses\nChapter 4\nHomework 4 due Feb 26Survey distribution due Feb 27\nLecture 6\n\n\n\nFeb 18\n\n\n\nLecture 7\n\n\nWeek 5\nFeb 23\nGraphing and describing patterns\nChapter 5\nHomework 5 due Mar 05\nLecture 8\n\n\n\nFeb 25\n\n\n\nLecture 9\n\n\nWeek 6\nMar 02\nResearch and causation\nChapter 6\nHomework 6 due Mar 12\nLecture 10\n\n\n\nMar 04\n\n\n\nLecture 11\n\n\nWeek 7\nMar 09\nControlled comparisons\nChapter 7\n\nLecture 12\n\n\n\nMar 11\n\n\nMidterm I\n\n\n\nWeek 8\nMar 16\n\nSpring Break\n\n\n\n\n\nMar 18\n\nSpring Break\n\n\n\n\nWeek 9\nMar 23\nInference\nChapter 8\nHomework 7 due Mar 26Survey practice I due Mar 27\nLecture 13\n\n\n\nMar 25\n\n\n\nLecture 14\n\n\nWeek 10\nMar 30\nHypothesis testing\nChapter 9\nHomework 8 due Apr 09\nLecture 15\n\n\n\nApr 01\n\n\n\nLecture 16\n\n\nWeek 11\nApr 06\nChi-2 and measures of variance/Correlation and Regression\nChapter 10 and Chapter 11\nHomework 9 due Apr 16\nLecture 17\n\n\n\nApr 08\n\n\n\nLecture 18\n\n\nWeek 12\nApr 13\nMultiple Regression\nChapter 12\nHomework 10 due Apr 23\nLecture 19\n\n\n\nApr 15\n\n\n\nLecture 20\n\n\nWeek 13\nApr 20\nAnalyzing residuals\nChapter 13\nSurvey practice II due May 01\nLecture 21\n\n\n\nApr 22\n\n\n\nLecture 22\n\n\nWeek 14\nApr 27\nLogistic regression\nChapter 14\nOptional Homework 11 due May 07\nLecture 23\n\n\n\nApr 29\n\n\n\nLecture 24\n\n\nWeek 15\nMay 04\nWrap up and review\nChapter 15\nFinal projectduring final exam period\nLecture 25\n\n\n\nMay 06\nMidterm",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "Some helpful links for students interested in learning more about political science, research methods, or R programming.\n\nTextbook Resources\n\nPoliSciData.com\n\nThis is the website for the course textbook. In addition to helpful guides and videos, they‚Äôve got an excellent collection of political science data sets that are free and online. If you‚Äôre interested in doing your own analyses, this is a great place to start. You might also want to check out their YouTube page.\n\n\n\n\nNews and Analysis\n\nGood Authority\n\nGood Authority is the successor to The Monkey Cage, a blog previously hosted by the Washington Post. Its a great place to read new research and analysis of current events from a polisci perspective.\n\nLSE Blogs\n\nCommentary and analysis of global and European politics hosted by the London School of Economics.\n\nFiveThirtyEight\n\nData-driven analysis and commentary on current events and sports. Now hosted by ABC News.\n\nPew Research\n\nA non-partisan think tank that tracks public opinion in the U.S. and abroad. Their Decoded Blog offers some really nice hands-on tutorials for anyone interested in working with public opinion data.\n\n\n\n\nR\nThere are a ton of great free resources for learning more about R, and this is by no means an exhaustive list, but these are some books and tutorials that I think are especially useful if you‚Äôre interested in learning more about using R for analysis.\n\nR for data science\n\nThis is a free e-book written, appropriately, for people who want to use R for data science. The book assumes some basic knowledge of R programming, but its an excellent resource if you want to learn how to do things like build your own database from scratch or scrape the web.\n\nhttps://rforpoliticalscience.com/\n\nA blog with short posts detailing packages, data sources, and other small projects and tips all aimed at R-using political scientists.\n\nBig Book of R\n\nLinks to hundreds of free, open-source R tutorials arranged by topic.",
    "crumbs": [
      "Additional Resources",
      "Links"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is a site for students taking GVPT 201 in Spring 2026. While the most important course material is stored on ELMS, I‚Äôm experimenting this semester with using an external site to host some code, data, and other instructional stuff. Don‚Äôt worry! If its essential, I‚Äôll post a link to it on the ELMS page.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a site for students taking GVPT 201 in Spring 2026. While the most important course material is stored on ELMS, I will occasionally post examples and other instructional materials and other cool stuff on this site."
  },
  {
    "objectID": "Weeks/Week 01/Week-template.html",
    "href": "Weeks/Week 01/Week-template.html",
    "title": "Week",
    "section": "",
    "text": "Welcome to GVPT 201! I hope everyone enjoyed the snow day. This week, we‚Äôre talking about the process of turning complex concepts into something measurable, and what can go wrong in the process."
  },
  {
    "objectID": "Weeks/Week 01/Week-template.html#lecture-slides",
    "href": "Weeks/Week 01/Week-template.html#lecture-slides",
    "title": "Week",
    "section": "Lecture slides",
    "text": "Lecture slides\n\nIntroductionsLecture 1\n\n\n\n\n\n\n\n\nClick here to view full screen. You can use your keypad to navigate the slides.\n\n\n\n\n\n\n&lt;a href=\"/Slides/slides_01.html\"&gt;&lt;/a&gt;\n\n\n\nClick here to view full screen. You can use your keypad to navigate the slides."
  },
  {
    "objectID": "Weeks/Week 01/Week-template.html#to-do",
    "href": "Weeks/Week 01/Week-template.html#to-do",
    "title": "Week",
    "section": "To-Do",
    "text": "To-Do\n\nRead chapter 1 of the textbook.\nInstall R and R-Studio by Friday so you‚Äôre ready for discussion sections.\nBe sure you‚Äôre checking the ELMS page for critical information."
  },
  {
    "objectID": "Slides/slides_07.html#review-of-some-concepts",
    "href": "Slides/slides_07.html#review-of-some-concepts",
    "title": "Inference",
    "section": "Review of some concepts",
    "text": "Review of some concepts\n\nMean (\\(\\mu\\))\n\nThe (arithmetic) mean or average of a variable is the sum of every element divided by the number of observations\n\n\n\n\nStandard deviation (\\(\\sigma\\))\n\nThe standard deviation of a measure of dispersion. It tells us how much things vary around the mean."
  },
  {
    "objectID": "Slides/slides_07.html#review-of-some-concepts-1",
    "href": "Slides/slides_07.html#review-of-some-concepts-1",
    "title": "Inference",
    "section": "Review of some concepts",
    "text": "Review of some concepts\n\nStandardization:\n\nWe can ‚Äúmean-center‚Äù a variable by subtracting its mean from each observation. Then we can divide each observation by the standard deviation. This will give us a variable with a mean of zero and standard deviation of 1. (We‚Äôll often refer to this standardized variable as ‚ÄúZ‚Äù or a ‚ÄúZ-score‚Äù.)\n\n\n\\[\n\\text{Z score} = \\frac{\\text{Deviation from the mean}}{\\text{Standard Deviation}}\n\\]"
  },
  {
    "objectID": "Slides/slides_07.html#distributions",
    "href": "Slides/slides_07.html#distributions",
    "title": "Inference",
    "section": "Distributions",
    "text": "Distributions\n\nProbability distribution\n\nA probability distribution is a function that describes the probability of different random values of a variable or statistic. If I know the distribution and its parameters for something, then I can make predictions about the probability of some outcome using the probability density function for that distribution."
  },
  {
    "objectID": "Slides/slides_07.html#the-normal-distribution",
    "href": "Slides/slides_07.html#the-normal-distribution",
    "title": "Inference",
    "section": "The normal distribution",
    "text": "The normal distribution\n\n\n\n\nThe normal distribution is a probability distribution that produces data that looks like this:\n\n\n\n\nThe normal distribution has two parameters: the mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)). If we know these parameters we can calculate the area under any set of points in this curve.\n\n\n\n\nSo, we can use this to make predictions like ‚Äúwhat % of observations would be 2 or Z scores above the mean?‚Äù"
  },
  {
    "objectID": "Slides/slides_07.html#the-central-limit-theorem",
    "href": "Slides/slides_07.html#the-central-limit-theorem",
    "title": "Inference",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nWhen I take a decent-sized random sample a continuous variable from a population with a fixed mean:\n\n\nI know the sample mean (\\(\\bar{x}\\)) is drawn from a normal distribution.\nI know the mean (\\(\\mu\\)) of this sampling distribution is equal to the population mean.\nI know the standard error of this sampling distribution is equal to \\(\\frac{\\sigma}{\\sqrt{n}}\\)\n\nSo: I know that 95% of my sample averages or proportions will be within \\(\\approx 1.96\\) standard errors of the correct answer (and any number of other probabilities based on the normal curve)"
  },
  {
    "objectID": "Slides/slides_07.html#margin-of-error-for-a-proportion",
    "href": "Slides/slides_07.html#margin-of-error-for-a-proportion",
    "title": "Inference",
    "section": "Margin of error for a proportion",
    "text": "Margin of error for a proportion\n\n\nIn the 2020 Census, \\(46.3\\%\\) of households were headed by a married couple.\n\nWhat is the probability that a random sample of 1,000 households would be over or under by \\(3\\%\\)?"
  },
  {
    "objectID": "Slides/slides_07.html#confidence-intervals",
    "href": "Slides/slides_07.html#confidence-intervals",
    "title": "Inference",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nInstead of asking ‚Äúhow likely is an error of ___ size?‚Äù confidence intervals ask ‚Äúwhat‚Äôs a range of values that is likely to contain the population parameter?‚Äù\n\nIn other words whats the range that would contain ____% of the sample means?"
  },
  {
    "objectID": "Slides/slides_07.html#estimating-sigma",
    "href": "Slides/slides_07.html#estimating-sigma",
    "title": "Inference",
    "section": "Estimating \\(\\sigma\\)",
    "text": "Estimating \\(\\sigma\\)\nHow do we estimate a standard error for a variable when the population standard deviation is unknown?\n\nIf the sample is large enough we can use the sample standard deviation itself to estimate the population standard deviation after a tiny correction:\n\n\nPopulation standard deviation:\n\\[\n\\sigma = \\sqrt{\\frac{\\sum_{i} (x_{i} - \\mu)^2}{n}}\n\\]\n\n\nSample standard deviation:\n\\[\ns = \\sqrt{\\frac{\\sum_{i} (x_{i} - \\mu)^2}{n-1}}\n\\]"
  },
  {
    "objectID": "Slides/slides_07.html#estimating-sigma-for-a-small-sample",
    "href": "Slides/slides_07.html#estimating-sigma-for-a-small-sample",
    "title": "Inference",
    "section": "Estimating \\(\\sigma\\) for a small sample",
    "text": "Estimating \\(\\sigma\\) for a small sample\nWhat if we don‚Äôt have a lot of observations?\n\n(prepare for a slight digression)"
  },
  {
    "objectID": "Slides/slides_07.html#estimating-sigma-3",
    "href": "Slides/slides_07.html#estimating-sigma-3",
    "title": "Inference",
    "section": "Estimating \\(\\sigma\\)",
    "text": "Estimating \\(\\sigma\\)\nWe‚Äôre trying to estimate the population standard deviation using the sample standard deviation. In large samples, these are going to be very close most of the time. In very small samples, the \\(s\\) will be biased toward zero. So in very small samples, we would tend to underestimate uncertainty."
  },
  {
    "objectID": "Slides/slides_07.html#students-t-distribution",
    "href": "Slides/slides_07.html#students-t-distribution",
    "title": "Inference",
    "section": "Student‚Äôs T Distribution",
    "text": "Student‚Äôs T Distribution\n\n\n\n\nRemember that the normal distribution has just two parameters: mean and standard deviation.\n\n\n\n\n‚ÄúStudent‚Äôs T‚Äù distribution has an extra parameter - degrees of freedom - which is equal to the sample size minus the number of parameters we‚Äôre trying to estimate.\n\n(For right now, this just means \\(n-1\\) because we‚Äôre just using the sample to estimate the population mean.)\n\n\n\n\n\nWhen df is low (less than 30) the T distribution has ‚Äúfatter tails‚Äù\n\n\n\n\nAround df &gt;= 30 it is basically indistinguishable from the normal."
  },
  {
    "objectID": "Slides/slides_05.html#spurious-relationships",
    "href": "Slides/slides_05.html#spurious-relationships",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\nWhy might we see a correlation between the amount of weekly protest activity and the number of flights to Hawaii?"
  },
  {
    "objectID": "Slides/slides_05.html#spurious-relationships-1",
    "href": "Slides/slides_05.html#spurious-relationships-1",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\nThe spurious correlation is happening because summer days have more protests and more flights to Hawaii because that‚Äôs when the weather is nice.\n\n\nHow do we resolve this?"
  },
  {
    "objectID": "Slides/slides_05.html#spurious-relationships-2",
    "href": "Slides/slides_05.html#spurious-relationships-2",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\n\nA simple fix here would be dis-aggregation: we split the data up based on the season and then we re-assess the same relationship within each group. This would ensure we were comparing summer flights to summer protests and non-summer flights to non-summer protests.\nIf the correlation is spurious, then this will make the observed relationship will disappear or potentially even reverse (go from positive to negative or vice-versa)"
  },
  {
    "objectID": "Slides/slides_05.html#spurious-relationships-3",
    "href": "Slides/slides_05.html#spurious-relationships-3",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\n\nThis process of splitting data up to make comparisons within groups is the basic intuition behind mathematically controlling for a confounder. (you‚Äôll often hear this described as ‚Äúholding constant‚Äù for a confounder)"
  },
  {
    "objectID": "Slides/slides_05.html#cra-vote",
    "href": "Slides/slides_05.html#cra-vote",
    "title": "Chapter 5: Controlled comparisons",
    "section": "1964 CRA vote",
    "text": "1964 CRA vote"
  },
  {
    "objectID": "Slides/slides_05.html#cra-vote-1",
    "href": "Slides/slides_05.html#cra-vote-1",
    "title": "Chapter 5: Controlled comparisons",
    "section": "1964 CRA vote",
    "text": "1964 CRA vote"
  },
  {
    "objectID": "Slides/slides_05.html#cra-vote-2",
    "href": "Slides/slides_05.html#cra-vote-2",
    "title": "Chapter 5: Controlled comparisons",
    "section": "1964 CRA vote",
    "text": "1964 CRA vote\nThe pattern looks different once we consider region:\n\n\n\n\nEffect of party in the north = 95 - 85 = 10\nEffect of party in the south = 9 - 0 = 9\nThe relationship flips direction and shrinks after accounting for region.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNorth\n\n\nSouth\n\n\n\n\n\nCRA vote\nDem\nRep\nDem\nRep\n\n\nyes\n145 (95%)\n136 (85%)\n8 (9%)\n0 (0%)\n\n\nno\n8 (5%)\n24 (15%)\n83 (91%)\n11 (100%)"
  },
  {
    "objectID": "Slides/slides_05.html#civil-rights-act",
    "href": "Slides/slides_05.html#civil-rights-act",
    "title": "Chapter 5: Controlled comparisons",
    "section": "1964 Civil Rights Act",
    "text": "1964 Civil Rights Act"
  },
  {
    "objectID": "Slides/slides_05.html#control-groups-vs.-control-variables",
    "href": "Slides/slides_05.html#control-groups-vs.-control-variables",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Control groups vs.¬†Control variables",
    "text": "Control groups vs.¬†Control variables\n\nThe language here tends to throw people off:\n\nControl groups are the baseline group in an experiment. The control group in a medical study would be the people who received the placebo treatment.\nControl variables are the confounding variables that we want to address by holding constant for their effects on the outcome.\n\n\n\nRandomization and control variables attempt to accomplish the same goals, but in different ways."
  },
  {
    "objectID": "Slides/slides_05.html#additive-relationships",
    "href": "Slides/slides_05.html#additive-relationships",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Additive Relationships",
    "text": "Additive Relationships\nIn an additive relationship, Z independently influences the outcome, but it doesn‚Äôt account for the relationship between X and Y\n\n\nExamples:\n\nBeing Republican and conservative both make people more likely to vote for Republican candidates.\nGDP and literacy rates both make countries more likely to be Democratic.\nGenetics and environment both impact life expectancy separately.\n\n\n\n\n\n\n\n\n\nmrdag\n\n\n\nZ\n\nZ (control)\n\n\n\nY\n\nY (DV)\n\n\n\nZ-&gt;Y\n\n\n\n\n\nX\n\nX (IV) \n\n\n\nX-&gt;Y"
  },
  {
    "objectID": "Slides/slides_05.html#interactive-relationship",
    "href": "Slides/slides_05.html#interactive-relationship",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Interactive Relationship",
    "text": "Interactive Relationship\nIn an interactive relationship, Z strengthens or weakens the effect of X on Y.\n\n\n\nWeight changes the effect of alcoholic drinks on blood alcohol level. (smaller people get drunk with fewer drinks, all else equal)\nIssue salience makes policy views more important. (i.e.¬†if a candidate talks a lot about abortion, abortion opinions will matter more for vote choice)\nState referenda make state policy more likely to align with public opinion.\n\n\n\n\n\n\n\n\n\nmrdag\n\n\n\nZ\n\nZ (control)\n\n\n\nX\n\nX (IV) \n\n\n\nZ-&gt;X\n\n\n\n\n\nY\n\nY (DV)\n\n\n\nX-&gt;Y"
  },
  {
    "objectID": "Slides/slides_05.html#using-a-cross-tab",
    "href": "Slides/slides_05.html#using-a-cross-tab",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Using a cross-tab",
    "text": "Using a cross-tab"
  },
  {
    "objectID": "Slides/slides_05.html#identifying-the-pattern",
    "href": "Slides/slides_05.html#identifying-the-pattern",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Identifying the pattern",
    "text": "Identifying the pattern\nTo characterize the pattern after control, you can ask yourself a series of questions."
  },
  {
    "objectID": "Slides/slides_05.html#mean-comparison-table",
    "href": "Slides/slides_05.html#mean-comparison-table",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Mean comparison table",
    "text": "Mean comparison table"
  },
  {
    "objectID": "Slides/slides_05.html#nominal-relationships",
    "href": "Slides/slides_05.html#nominal-relationships",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Nominal Relationships",
    "text": "Nominal Relationships\n\nFor data that are nominal, it may not make sense to talk about the ‚Äúdirection‚Äù, but your book suggests using treating the left-most category as the baseline group and then comparing based on that.\n\n\n\n\n\n% unionization\n\n\n\n\n\n\n\n\n\niv\nSouth\nNortheast\nMidwest\nWest\n\n\n\n\nBiden 20\n7.6\n(4)\n14.4\n(9)\n12.8\n(4)\n12.4\n(8)\n\n\nTrump 20\n5.9\n(12)\n0\n(0)\n8.5\n(8)\n9.5\n(5)"
  },
  {
    "objectID": "Slides/slides_05.html#when-to-use-what",
    "href": "Slides/slides_05.html#when-to-use-what",
    "title": "Chapter 5: Controlled comparisons",
    "section": "When to use what",
    "text": "When to use what\n\n\nUse a cross tab when all variables are categorical\nUse a mean comparison when the DV is interval and the control and IV are categorical\n\nKeep in mind that, if the DV is dichotomous, you can basically treat it as numeric and the ‚Äúmean‚Äù is equal to the proportion of ‚ÄúYes‚Äù or ‚ÄúTRUE‚Äù values for each group.\n\nConsider collapsing some categories to simplify analyses and ensure you have sufficient data. For instance, if a response ranges from Strongly Agree to Strongly Disagree, you might collapse it down to just 2-3 categories."
  },
  {
    "objectID": "Slides/slides_05.html#what-about-interval-level-relationships",
    "href": "Slides/slides_05.html#what-about-interval-level-relationships",
    "title": "Chapter 5: Controlled comparisons",
    "section": "What about interval level relationships?",
    "text": "What about interval level relationships?\n\nYou can collapse interval data into categories and then use a mean comparison\nMore often, we‚Äôll use regression analysis:\n\nIn essence, we‚Äôll draw a ‚Äúline of best fit‚Äù through the values of X and Y"
  },
  {
    "objectID": "Slides/slides_05.html#other-methods-for-addressing-confounding",
    "href": "Slides/slides_05.html#other-methods-for-addressing-confounding",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Other methods for addressing confounding",
    "text": "Other methods for addressing confounding"
  },
  {
    "objectID": "Slides/slides_05.html#matching",
    "href": "Slides/slides_05.html#matching",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Matching",
    "text": "Matching\n\nIdentify similar cases at each level of the IV. For instance, find Republicans and Democrats of similar ages.\nDrop any cases that can‚Äôt be matched.\nRe-weight the cases to ensure balance, and then assess the effect."
  },
  {
    "objectID": "Slides/slides_05.html#difference-in-differences",
    "href": "Slides/slides_05.html#difference-in-differences",
    "title": "Chapter 5: Controlled comparisons",
    "section": "Difference-in-differences",
    "text": "Difference-in-differences\n\n\n\nMeasure outcomes for two groups at two different times\nIf you can assume the trend for both groups is the same, then the difference-in-differences at time 2 is the effect of the treatment."
  },
  {
    "objectID": "Slides/slides_03.html#why-questions",
    "href": "Slides/slides_03.html#why-questions",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "‚ÄúWhy‚Äù questions",
    "text": "‚ÄúWhy‚Äù questions\n\n‚ÄúWhy questions‚Äù\n\nWhy do some eligible voters fail to turn out on election day?\nWhat explains variation in gun policies across U.S. states?\nWhy did communist revolutions happen in China and Russia but not Europe or the United States?"
  },
  {
    "objectID": "Slides/slides_03.html#theoretical-scope",
    "href": "Slides/slides_03.html#theoretical-scope",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Theoretical Scope",
    "text": "Theoretical Scope\nTheories vary in their scope:\n\n\nEarly sociologists like Marx, Durkheim, Weber attempted to develop all-encompassing ‚Äúlaws‚Äù of political/social/historical change. These are sometimes called ‚Äúgrand theories‚Äù\nContemporary social sciences are less ambitious, and so its more common to propose ‚Äúmiddle-range‚Äù theories that seek to explain a smaller number regularities in one area.\n\nHowever, they may draw on ‚Äúgrand theories‚Äù either implicitly or explicitly."
  },
  {
    "objectID": "Slides/slides_03.html#paths-to-modernity",
    "href": "Slides/slides_03.html#paths-to-modernity",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Paths to Modernity",
    "text": "Paths to Modernity\nWhat explains differences in the ‚Äúpath to modernity‚Äù across different countries during the 20th century?\n\nFree markets/Democracy in the U.S. and England\nFascism in Germany and Japan\nCommunism in Russia and China"
  },
  {
    "objectID": "Slides/slides_03.html#paths-to-modernity-1",
    "href": "Slides/slides_03.html#paths-to-modernity-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Paths to Modernity",
    "text": "Paths to Modernity\n\n\nBarrington Moore: Classes have unique and conflicting interests. Conflicts over these interests come to the forefront during industrialization. The outcomes of these class conflicts shape the political and economic system.\n\n\nFascist states emerge when the landed aristocracy wins\nCommunist states emerge when the peasant class wins\nDemocracies emerge when the bourgeois (middle class) wins."
  },
  {
    "objectID": "Slides/slides_03.html#paths-to-modernity-2",
    "href": "Slides/slides_03.html#paths-to-modernity-2",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Paths to Modernity",
    "text": "Paths to Modernity\n\n\nMoore‚Äôs theory borrows assumptions from a (sociological) Marxist grand theory about class conflict\nHe ‚Äútests‚Äù it by showing how it fits the selected cases.\nIt can be used and refined to generate a set of empirical expectations about what factors should matter for democratization. For instance, we might expect:\n\nStates with larger agricultural sectors during industrialization to be less democratic today (compared to states with smaller agricultural sectors)\nStates with higher literacy rates during industrialization to be more democratic (compared to states with lower literacy rates)"
  },
  {
    "objectID": "Slides/slides_03.html#theories-survey-answers",
    "href": "Slides/slides_03.html#theories-survey-answers",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Theories: survey answers",
    "text": "Theories: survey answers\nWhat explains inconsistent answers to survey questions?\n\n\n\n\nAsking the same people the same questions a few months apart yields surprisingly unpredictable results.\nSmall changes in question wording, ordering of choices, or survey context cause big changes in outcomes\n\n\n\n\n\n\n\n\n\n\n\n\nData from the 1980 ANES panel survey (reproduced from Zaller 1992)"
  },
  {
    "objectID": "Slides/slides_03.html#theories-voting",
    "href": "Slides/slides_03.html#theories-voting",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Theories: voting",
    "text": "Theories: voting\nWhy do people vote?\n\n\nSince politicians generally offer public goods, you can enjoy the benefits of your preferred candidate winning even if you don‚Äôt vote\nSince voting has costs (even though they‚Äôre small) free riding can be preferable to actually turning out if the costs outweigh the benefits."
  },
  {
    "objectID": "Slides/slides_03.html#assessing-theories",
    "href": "Slides/slides_03.html#assessing-theories",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Assessing Theories",
    "text": "Assessing Theories\n\n\n\nTheories require simplified representations of a complex reality\nUtility, not ‚Äútruth‚Äù: theoretical models invariably contain assumptions and they‚Äôre probably violated in practice.\n\n\n\n\n\nGeorge Box: ‚ÄúAll models are wrong, but some are useful‚Äù"
  },
  {
    "objectID": "Slides/slides_03.html#hypotheses-1",
    "href": "Slides/slides_03.html#hypotheses-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Hypotheses",
    "text": "Hypotheses\nComponents:\n\nUnit of analysis\nDependent variable\nIndependent variable\nDirection of the predicted relationship\n\n\nGood hypotheses inevitably involve comparative language (higher/lower/more/less/increase/decrease/better/worse)"
  },
  {
    "objectID": "Slides/slides_03.html#hypothesis-template",
    "href": "Slides/slides_03.html#hypothesis-template",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Hypothesis Template",
    "text": "Hypothesis Template\nIn a comparison of [unit of analysis], those having [one value on the independent variable] will be [more/less] likely to have [one value on the dependent variable] than those having a [different value on the independent variable]."
  },
  {
    "objectID": "Slides/slides_03.html#hypothesis-template-1",
    "href": "Slides/slides_03.html#hypothesis-template-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Hypothesis Template",
    "text": "Hypothesis Template\nIn a comparison of [voters], those having [stronger political views] will be more likely to have [a higher likelihood of turnout] than those having a [weaker views].\n\n\nUnit of analysis: voters\nIV: strength of political views\nDV: turnout\nRelationship: strength increases turnout"
  },
  {
    "objectID": "Slides/slides_03.html#hypothesis-template-2",
    "href": "Slides/slides_03.html#hypothesis-template-2",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Hypothesis Template",
    "text": "Hypothesis Template\nIn a comparison of [states], those having [a larger middle class during industrialization] will be more likely to have [democracy] than those having a [a smaller middle class].\n\n\nUnit of analysis: states\nIV: size of the middle class\nDV: democracy\nRelationship: middle class increases likelihood of democracy"
  },
  {
    "objectID": "Slides/slides_03.html#hypothesis-template-3",
    "href": "Slides/slides_03.html#hypothesis-template-3",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Hypothesis Template",
    "text": "Hypothesis Template\nIn a comparison of [survey respondents], those having [higher levels of attention to politics] will be more likely to have [consistent responses] than those having a [lower levels of attention to politics].\n\n\nUnit of analysis: Survey respondents\nIV: level of attention\nDV: response consistency\nRelationship: attention increases consistency"
  },
  {
    "objectID": "Slides/slides_03.html#complex-relationships",
    "href": "Slides/slides_03.html#complex-relationships",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Complex Relationships",
    "text": "Complex Relationships\nGood hypotheses may suggest a more complex set of relationships than just ‚Äúpositive/negative‚Äù. They could propose conditional/interactive/curvilinear relationships as well.\n\nThe ‚Äúoil curse‚Äù\n\nIn a comparison of [countries], those having [higher levels of GDP] will be [more likely to be democratic] compared to [countries with lower GDP], [however, this relationship will not hold for countries that get rich from oil exports.]\n\n\n\nRetrospective voting:\n\nIn a comparison of [voters], those having [lower levels of attention to politics] will be [more likely to vote for the incumbent when the economy is doing well]. Those having [higher levels of attention to politics] will be [more likely to vote based on policy preferences regardless of the state of the economy]"
  },
  {
    "objectID": "Slides/slides_03.html#bad-hypotheses",
    "href": "Slides/slides_03.html#bad-hypotheses",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Bad hypotheses",
    "text": "Bad hypotheses\n\n\nThe main determinant of war is the distribution of power in the international system.\nIn comparing individuals, annual income and the level of education are related.\nDemocracies are peaceful. In comparing individuals, some people are more likely to favor the death penalty than others."
  },
  {
    "objectID": "Slides/slides_03.html#cross-tabulation-step-1",
    "href": "Slides/slides_03.html#cross-tabulation-step-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Cross tabulation: Step 1",
    "text": "Cross tabulation: Step 1\nStart by calculating the number of observations with each value of each category:\n\n\n\n\n\n\n\n\niv\ndv\n\n\n\n\nHIGH\nNo\n\n\nHIGH\nNo\n\n\nLOW\nNo\n\n\nHIGH\nYes\n\n\nHIGH\nYes\n\n\nHIGH\nYes\n\n\nHIGH\nYes\n\n\nLOW\nYes\n\n\nLOW\nYes\n\n\nLOW\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1\n2\n\n\nYes\n3\n4\n\n\n\n\n\nTotal\n4\n6"
  },
  {
    "objectID": "Slides/slides_03.html#cross-tabulation-step-2",
    "href": "Slides/slides_03.html#cross-tabulation-step-2",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Cross tabulation: Step 2",
    "text": "Cross tabulation: Step 2\nThen, calculate the proportion/percentage of observations among each value of the IV.\nIf the independent variable is in the columns, then the columns should sum to 100%.\nIf the independent variable is in the rows, then the rows should sum to 100%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1\n2\n\n\nYes\n3\n4\n\n\n\n\n\nTotal\n4\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1 (25%)\n2 (33%)\n\n\nYes\n3 (75%)\n4 (67%)\n\n\n\n\n\nTotal\n4\n6"
  },
  {
    "objectID": "Slides/slides_03.html#cross-tabulation-interpretation",
    "href": "Slides/slides_03.html#cross-tabulation-interpretation",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Cross tabulation: interpretation",
    "text": "Cross tabulation: interpretation\nLook at what happens to the DV at different values of the IV. If your variables are ordinal, you should be able to identify a direction of the effect.\nThe proportion of ‚ÄúYes‚Äù values decreases as the IV goes from lower to higher, so this is a negative or inverse relationship.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1 (25%)\n2 (33%)\n\n\nYes\n3 (75%)\n4 (67%)\n\n\n\n\n\nTotal\n4\n6\n\n\n\n\n\n\n\n\n\nUsing a bar graph or line graph can make these relationships easier to spot:"
  },
  {
    "objectID": "Slides/slides_03.html#cross-tabulation-notes",
    "href": "Slides/slides_03.html#cross-tabulation-notes",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Cross tabulation: notes",
    "text": "Cross tabulation: notes\n\nKey rule: always calculate percentages or proportions by categories of the independent variable.\n\nThis allows you to compare groups that are different sizes.\n\nIf one or both variables are interval-level, you can bin them in order to use them in a cross tab. For instance, you could separate an interval like into a series of age ranges."
  },
  {
    "objectID": "Slides/slides_03.html#cross-tabulation-example",
    "href": "Slides/slides_03.html#cross-tabulation-example",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Cross tabulation: example",
    "text": "Cross tabulation: example\nHypothesis: in a comparison of individuals, independents are less likely to turn out to vote compared to people who support one party or another.\n\nHow should I calculate proportions here?\n\n\n\n\nVoter Turnout in 2020 by party ID\n\n\n\n\n\n\n\n\n\n\nParty ID\n\n\n\nturnout2020\nDemocrat\nIndependent\nRepublican\n\n\n\n\n0. Did not vote\n335\n316\n382\n\n\n1. Voted\n3160\n560\n2714"
  },
  {
    "objectID": "Slides/slides_03.html#cross-tabulation-example-1",
    "href": "Slides/slides_03.html#cross-tabulation-example-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Cross tabulation: example",
    "text": "Cross tabulation: example\nAre these results generally consistent with my hypothesis?\n\n\n\n\n\n\nVoter Turnout in 2020 by party ID\n\n\n\n\n\n\n\n\n\n\nParty ID\n\n\n\nturnout2020\nDemocrat\nIndependent\nRepublican\n\n\n\n\n0. Did not vote\n335 (10%)\n316 (36%)\n382 (12%)\n\n\n1. Voted\n3160 (90%)\n560 (64%)\n2714 (88%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we think of party ID as an ordered variable, this is a curvilinear relationship."
  },
  {
    "objectID": "Slides/slides_03.html#rowcolumn-percentages",
    "href": "Slides/slides_03.html#rowcolumn-percentages",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Row/Column percentages",
    "text": "Row/Column percentages\nWhat happens if I calculate % among the values of the DV?\nHere‚Äôs the relationship between education and voter turnout with % calculated on education level:\n\n\n\n\nVoter Turnout in 2020 by highest level of education completed\n\n\n\n\n\n\n\n\n\n\n\n\nEducation\n\n\n\nturnout2020\n1. Less than high school credential\n2. High school credential\n3. Some post-high school, no bachelor's degree\n4. Bachelor's degree\n5. Graduate degree\n\n\n\n\n0. Did not vote\n130 (41%)\n286 (24%)\n380 (15%)\n135 (7%)\n91 (6%)\n\n\n1. Voted\n185 (59%)\n883 (76%)\n2148 (85%)\n1749 (93%)\n1388 (94%)\n\n\n\nNote: \n\n\n\n\n\n\n\n Column % in parentheses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe results suggest a positive or direct relationship: as education increases, so does the % turnout."
  },
  {
    "objectID": "Slides/slides_03.html#rowcolumn-percentages-1",
    "href": "Slides/slides_03.html#rowcolumn-percentages-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Row/Column percentages",
    "text": "Row/Column percentages\nWhat happens if I calculate % among the values of the DV?\nHere‚Äôs the relationship between education and voter turnout with % calculated across voter turnout\n\n\n\n\nVoter Turnout in 2020 by highest level of education completed\n\n\n\n\n\n\n\n\n\n\n\n\nEducation\n\n\n\nturnout2020\n1. Less than high school credential\n2. High school credential\n3. Some post-high school, no bachelor's degree\n4. Bachelor's degree\n5. Graduate degree\n\n\n\n\n0. Did not vote\n130 (13%)\n286 (28%)\n380 (37%)\n135 (13%)\n91 (9%)\n\n\n1. Voted\n185 (3%)\n883 (14%)\n2148 (34%)\n1749 (28%)\n1388 (22%)\n\n\n\nNote: \n\n\n\n\n\n\n\n Row % in parentheses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, the results can give the misleading impression that there‚Äôs a curvilinear relationship: turnout drops off for Bachelor‚Äôs Degrees and above."
  },
  {
    "objectID": "Slides/slides_03.html#rowcolumn-percentages-2",
    "href": "Slides/slides_03.html#rowcolumn-percentages-2",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Row/Column percentages",
    "text": "Row/Column percentages\nEither of these tables might be a valid way to look at these data, but they answer slightly different questions:\n\n\nIf I want to compare turnout at different levels of education, then I need to calculate % turnout among people with different levels of education.\nIf I want to compare education among voters and non-voters, then I need to calculate % education among people who voted and didn‚Äôt vote.\nWhich variable is the IV or DV is sometimes a theoretical question, but in this case its unlikely that voting is causing people to become more educated, so it probably doesn‚Äôt make sense to calculate percentages by voting vs.¬†non-voting."
  },
  {
    "objectID": "Slides/slides_03.html#mean-comparison-1",
    "href": "Slides/slides_03.html#mean-comparison-1",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Mean Comparison",
    "text": "Mean Comparison\nGDP data has been grouped into five categories, so now I just need to calculate the average of CO2 emissions within each group of the ordinal IV:\n\n\n\n\nGDP Per capita range\nCO2 emissions per capita\n\n\n\n\n1. $3k or less\n0.3128312\n\n\n2. $3k to $10k\n1.2680574\n\n\n3. $10k to $25k\n4.4065669\n\n\n4. $25k to $45k\n8.0307610\n\n\n5. $45k or more\n12.3134306\n\n\n\n\n\n\n\nIs this generally consistent with expectations?"
  },
  {
    "objectID": "Slides/slides_03.html#mean-comparison-2",
    "href": "Slides/slides_03.html#mean-comparison-2",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Mean Comparison",
    "text": "Mean Comparison\nHere again, the relationship can be easier to conceptualize if we plot it."
  },
  {
    "objectID": "Slides/slides_03.html#comparing-boxplots",
    "href": "Slides/slides_03.html#comparing-boxplots",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Comparing Boxplots",
    "text": "Comparing Boxplots"
  },
  {
    "objectID": "Slides/slides_03.html#curvilinear-relationships",
    "href": "Slides/slides_03.html#curvilinear-relationships",
    "title": "Chapter 3: Theories, hypotheses, and comparisons",
    "section": "Curvilinear Relationships",
    "text": "Curvilinear Relationships\nA relationship like this will rarely be perfectly straight, so ‚Äúlinearity‚Äù and ‚Äúcurvilinearity‚Äù are partly a matter of degree, but there are some cases where there is a clear ‚ÄúU‚Äù shape to the relationship:\n\n\n\n\n\n\niv\ndv\n\n\n\n\n1. Extremely liberal\n6.314\n\n\n2. Liberal\n5.685\n\n\n3. Slightly liberal\n5.001\n\n\n4. Moderate; middle of the road\n4.651\n\n\n5. Slightly conservative\n4.636\n\n\n6. Conservative\n4.974\n\n\n7. Extremely conservative\n5.363"
  },
  {
    "objectID": "Slides/slides_02-2.html#measures-of-central-tendency",
    "href": "Slides/slides_02-2.html#measures-of-central-tendency",
    "title": "Visualization",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\n(some things you probably remember from school)"
  },
  {
    "objectID": "Slides/slides_02-2.html#central-tendency",
    "href": "Slides/slides_02-2.html#central-tendency",
    "title": "Visualization",
    "section": "Central Tendency",
    "text": "Central Tendency\n\n\n\n\n\n\n\nNominal\nOrdinal\nInterval\n\n\n\n\nMean\n‚ùå\n‚ùå\n‚úÖ\n\n\nMedian\n‚ùå\n‚úÖ\n‚úÖ\n\n\nMode\n‚úÖ\n‚úÖ\n‚úÖ"
  },
  {
    "objectID": "Slides/slides_02-2.html#measures-of-dispersion",
    "href": "Slides/slides_02-2.html#measures-of-dispersion",
    "title": "Visualization",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion"
  },
  {
    "objectID": "Slides/slides_02-2.html#dispersion",
    "href": "Slides/slides_02-2.html#dispersion",
    "title": "Visualization",
    "section": "Dispersion",
    "text": "Dispersion\n\n\n\n\n\n\n\n\nNominal\nOrdinal\nInterval\n\n\n\n\nStandard Deviation\n‚ùå\n‚ùå\n‚úÖ\n\n\nIQR\n‚ùå\n‚úÖ\n‚úÖ"
  },
  {
    "objectID": "Slides/slides_02-2.html#skew",
    "href": "Slides/slides_02-2.html#skew",
    "title": "Visualization",
    "section": "Skew",
    "text": "Skew\nSkew refers to the degree of asymmetry in data."
  },
  {
    "objectID": "Slides/slides_00.html#lecture",
    "href": "Slides/slides_00.html#lecture",
    "title": "Introductions",
    "section": "Lecture",
    "text": "Lecture\nThis is what you‚Äôre doing right now. Expect something very much like this.\n\nChoices\n\n\nAttend in person (this is the only format where you can ask questions!)\nWatch Zoom (check the Zoom tab on ELMS)\nWatch recordings on ELMS page.\n\n\n\n\nDue dates listed on ELMS are hard deadlines."
  },
  {
    "objectID": "Slides/slides_00.html#discussion-sections",
    "href": "Slides/slides_00.html#discussion-sections",
    "title": "Introductions",
    "section": "Discussion sections",
    "text": "Discussion sections\n\n\nEvery Friday, led by your TA\nJoin in person or on Zoom.\n\nZoom participants must have cameras on during the class\n\nAttendance is mandatory and participation is 10% of your grade\n\nRecordings will still be on ELMS in the ‚ÄúSection Recordings‚Äù folder of the Panopto tab\n\nThis is your best chance to ask homework questions, get feedback, and clarify concepts, so come prepared. (Read workbook and look at homework beforehand)"
  },
  {
    "objectID": "Slides/slides_00.html#resources",
    "href": "Slides/slides_00.html#resources",
    "title": "Introductions",
    "section": "Resources",
    "text": "Resources\nThere‚Äôs additional materials on the syllabus.\nGoing forward I will generally try to link study materials on the modules tab in ELMS."
  },
  {
    "objectID": "Slides/slides_00.html#political-science-research",
    "href": "Slides/slides_00.html#political-science-research",
    "title": "Introductions",
    "section": "Political Science Research",
    "text": "Political Science Research\n\n\nNormative Research\n‚ÄúOught‚Äù questions\n\nWhat constitutes a just society?\nWhat are the qualities of a good leader?\nWhat obligations do citizens have towards their governments?\n\n\nEmpirical Research\n‚ÄúIs/Are‚Äù questions\n\nAre democracies less likely to go to war compared to autocracies?\nDo protests prompt political change?\nWhen are political parties most likely to be unified around a shared platform or ideology?"
  },
  {
    "objectID": "Slides/slides_00.html#political-science-research-1",
    "href": "Slides/slides_00.html#political-science-research-1",
    "title": "Introductions",
    "section": "Political Science Research",
    "text": "Political Science Research\nThis course will focus primarily on the empirical and quantitative aspects of research.\n\nBut ideally, these goals should inform each other."
  },
  {
    "objectID": "Slides/slides_00.html#empirical-research-goals",
    "href": "Slides/slides_00.html#empirical-research-goals",
    "title": "Introductions",
    "section": "Empirical Research: goals",
    "text": "Empirical Research: goals\n\nIdentify a research question\nDefine key concepts\nFormulate a testable hypothesis\nCollect data, conduct analysis, and assess results\nCollectively: accumulate knowledge about the world"
  },
  {
    "objectID": "Slides/slides_00.html#empirical-research-stats",
    "href": "Slides/slides_00.html#empirical-research-stats",
    "title": "Introductions",
    "section": "Empirical Research: Stats",
    "text": "Empirical Research: Stats\n\n\nNumbers are for nerds, but you need some stats and basic programming skills to get through this course, this program, and probably your career and for general life stuff."
  },
  {
    "objectID": "Slides/slides_00.html#conceptual-outline-of-the-course",
    "href": "Slides/slides_00.html#conceptual-outline-of-the-course",
    "title": "Introductions",
    "section": "Conceptual Outline of the course",
    "text": "Conceptual Outline of the course\n\nWeeks 1 through 3: How to measure stuff and why it matters\nWeeks 4 through 8: Description, comparison, and hypotheses\nWeeks 9 through 10: Inference and statistical tests\nWeeks 11 through 14: Correlation and regression analysis"
  },
  {
    "objectID": "Slides/slides_00.html#grades",
    "href": "Slides/slides_00.html#grades",
    "title": "Introductions",
    "section": "Grades",
    "text": "Grades\n\n\nWorkbook HW (25%): R coding, usually due on Thursdays at midnight\nSurvey analysis (35%): design, distribute, and analyze a (non-representative) public opinion survey.\n\nBiggest component is an end-of-term data analysis paper\n\nExams (25%): open-notes/open book exams administered through ELMS.\nSection participation (10%): Based on engagement, not participation alone.\nLab (5%): participate in 3 studies conducted by GVPT faculty and students."
  },
  {
    "objectID": "Resources.html",
    "href": "Resources.html",
    "title": "Resources",
    "section": "",
    "text": "Additional resources and tips for GVPT 201 students."
  },
  {
    "objectID": "GVPT201_Syllabus.html",
    "href": "GVPT201_Syllabus.html",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "",
    "text": "Welcome to GVPT 201! This class is an introduction to the basics of political science research. We‚Äôll will begin by discussing how to formulate an empirical research question, then progress through the process of data collection, description and visualization, and finally testing a hypothesis and quantifying uncertainty. By the end of the course, you should have a solid working understanding of how we can use a scientific approach to answer (some) questions about the political world.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#instructor",
    "href": "GVPT201_Syllabus.html#instructor",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Instructor",
    "text": "Instructor\nName: Neil Lund\nEmail: nlund@umd.edu (please do not contact me through ELMS)\nOffice: 1140C Tydings Hall\nOffice Hours: Tuesday/Thursday 11:15 PM to 1:30 PM or by appointment",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#meetings",
    "href": "GVPT201_Syllabus.html#meetings",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Meetings",
    "text": "Meetings\n\nLecture 1: Monday-Wednesday 1:00 - 1:50pm Tydings 0130\nLecture 2: Monday-Wednesday 2:00 - 2:50pm Tydings 0117\nFriday Discussion: Check Testudo for schedule\n\nOtherwise otherwise noted, all class lecture meetings will be available over Zoom. Recordings will also be uploaded to ELMS. Check the ELMS page for additional detail.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#teaching-team",
    "href": "GVPT201_Syllabus.html#teaching-team",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Teaching Team",
    "text": "Teaching Team\nGraduate Teaching Assistant\n\n\n\n\n\n\n\nName\nEmail\n\n\n\n\nSonia Vargas\nsvargas@umd.edu\n\n\n\nUndergraduate Teaching Assistants\n\n\n\n\n\n\n\nName\nEmail\n\n\n\n\nAlexa Tira\natira@terpmail.umd.edu\n\n\nHeidi Medrano Guerra\nbnevglos@terpmail.umd.edu\n\n\nKatelyn Keller\ncliddle1@terpmail.umd.edu\n\n\nDean Truong\ndtruong6@terpmail.umd.edu\n\n\nCharles Liddle\nhbernst1@terpmail.umd.edu\n\n\nSumit Jani\nhmedrano@terpmail.umd.edu\n\n\nHannah Bernstein\njlawren9@terpmail.umd.edu\n\n\nBen Nevgloski\nkkeller7@terpmail.umd.edu\n\n\nJayme Lawrence\nsjani@terpmail.umd.edu",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#books",
    "href": "GVPT201_Syllabus.html#books",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Books",
    "text": "Books\n\nTextbook: Philip H. Pollock III. and Barry C. Edwards. 2024. The Essentials of Political Analysis Seventh Edition. Washington D.C. Sage and CQ Press. (Required).\nWorkbook: Philip H. Pollock III. and Barry C. Edwards. 2023. An R Companion to Political Analysis. Third Edition. Washington D.C. Sage and CQ Press. (Required).\n\nPlease note: the content changes enough between different editions of this textbook that it unfortunately is not really feasible to get by with an older edition. Students are encouraged to look for a used copy if they can find it.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#r-and-r-studio",
    "href": "GVPT201_Syllabus.html#r-and-r-studio",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "R and R-studio",
    "text": "R and R-studio\nYou will be using the R programming language for this course. R is completely FREE and works with any operating system. There are instructions on how to download R and the associated data files/packages for the homeworks in the workbook.\nYou also need to download R-Studio. You can get the free version. It‚Äôs the first option on this page.\nWe have several resources to assist you in learning the software:\n\nWe have recorded video lectures covering the material in each chapter in the R workbook. These videos are available in the workbook folder on PANOPTO (ELMS).\nThe professor will devote a portion of lecture time to R and the survey. Therefore, every week you can ask questions about R in class.\nIn Friday sections the TA‚Äôs will cover the R homework due the following Thursday and help you work on the survey. Therefore, every week you can ask questions about R and the survey in section.\n\nWhile we are happy to help you in understanding how to use R, we can only offer limited support when it comes to issues installing R onto your device. If for some reason your computer is not working you may be able to access the cloud-based Rstudio instance available to BSOS students.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#grade-components",
    "href": "GVPT201_Syllabus.html#grade-components",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Grade components",
    "text": "Grade components\nGrades are a percentage out of 780 possible points. The points will be distributed as follows:\n\nWorkbook Homework (25%)\nThese will be short assignments from the workbook that you will submit through ELMS. In order to receive credit you must attach an R script that shows your work along with your submission.\nYour lowest assignment grade will be dropped.\n\n\nExams (25%)\nThere will be two open-notes/open book exams administered through ELMS. They will cover materials from the lecture, textbook, and discussion sections. While they aren‚Äôt cumulative, concepts from the first half of the course will be relevant to the second half, so there may be some overlap for the second exam.\n\n\nSurvey (35%)\n\nPilot Design\n\nDuring lecture and discussion sections, students will work with me and the TA‚Äôs to design a battery of questions. Students will workshop these questions with each other and individually submit questions they would like to see on the survey. The Professor will choose the finals set of questions and program the survey. Once this is complete, the Professor will distribute this draft as the ‚Äúpilot‚Äù survey.\n\nPilot Analysis\n\nPilot analysis: After the pilot survey has been in the field for about a week, the Professor will release the data to the students. Students will have to complete a basic analysis of the pilot data. In addition to the respondents‚Äô answers to the questions, students are asked to consider the instrument itself. Did they find any questions confusing? Offensive? Needlessly complicated? Etc. Based on this feedback, the teaching staff will edit the survey instrument.\n\nVerification of Survey Distribution\n\nOnce the final question wording has been determined, students will be responsible for distributing the survey to as wide a range of people as possible via social networking sites, such as Facebook and Twitter, and other means of communication. You can also post it on websites like Reddit and distribute via email. Students will have to provide proof of distribution in the form of a screenshot. The survey will be in the field for approximately two weeks. Students are expected to promote and distribute the survey during this time.\n\nFinal Write-up\n\nThe final survey write up will be three memos (two ‚Äúpractice‚Äù that will take the form of ‚Äúquizzes‚Äù online, and one final one, which will be submitted as a paper) on the data gathered via the class survey. We will provide more detailed guidelines closer to the due dates. The memos are not weighted equally; the last one is weighted most heavily. Grades will be based on consistency of 8 the analytical argument, demonstration of cumulative mastery of the material from the course, and clarity of writing. The detailed rubric for the paper is available on ELMS.\n\n\n\n\nSection Participation (10%)\nSection: Students are expected to have completed all of the assigned readings and homework for each section and be prepared to discuss them. Attendance (in person or via zoom with the camera on) is mandatory and teaching assistants record participation in section.\n(Note that your grade here is based on your participation and engagement. Attendance alone is necessary, but not sufficient for earning full credit.)\n\n\nExperimental Lab (5%)\nThis class will also give credit to students who take part in studies conducted by GVPT faculty and graduate students. Each study will take about 20-30 minutes to complete. If you prefer not to serve as a participant, you may elect to satisfy the requirement by completing an alternate assignment (HW 13). However, you must notify the Research Administrator Woohyeon Kim (whkim@umd.edu) before the last day of schedule adjustment for the semester if you wish to register for the alternate assignment. Students will receive an email with further instructions about participation when the studies are available.\nStudents who are under 18 years of age must obtain parental permission to participate in research. If you are under 18, please contact Jordan James Anthony Spencer jspeck13@umd.edu and he will provide you with instructions on how to participate in the research studies. Alternate assignments cannot be used to make up for a study at the end of the semester.\n\n\nLate work\nBy default, all assignments will be due by 11:59 PM on their respective due dates. Assignments turned in after the deadline will receive a 20% penalty, and an additional 10 percentage points will be deducted for each additional day late.\nThis penalty can be waived if you have a documented excuse such as a doctor‚Äôs note, letter from a therapist, court order barring you from doing homework etc.\nFor regular homework assignments, students may provide a one-time self-signed excuse note to receive a 24 hour extension on a non-major grading event such as a homework assignment. See this page for a template. This policy does not apply to exams or the final project.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#grade-scale",
    "href": "GVPT201_Syllabus.html#grade-scale",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Grade Scale",
    "text": "Grade Scale\n\n\n\n\n\n\n\n\n% Grade\nLetter Grade\n\n\n\n\n97-100\nA+\n\n\n&lt; 97-94\nA\n\n\n&lt; 94-90\nA-\n\n\n&lt; 90-87\nB+\n\n\n&lt; 87-84\nB\n\n\n&lt; 84-80\nB-\n\n\n&lt; 80-77\nC+\n\n\n&lt; 77-74\nC\n\n\n&lt; 74-70\nC-\n\n\n&lt; 70-67\nD+\n\n\n&lt; 67-64\nD\n\n\n&lt; 64-61\nD-\n\n\n&lt; 61\nF",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#ai-use",
    "href": "GVPT201_Syllabus.html#ai-use",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "AI use",
    "text": "AI use\nIn this class, you may use AI tools (ChatGPT, Gemini, Claude etc.) for brainstorming and research only. Under no circumstances should you submit work (coding or analysis) that you didn‚Äôt write yourself or that you can‚Äôt explain to another person or effectively replicate on your own. If you are unsure whether a specific use-case is acceptable, please reach out to me for a clarification.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#class-communication",
    "href": "GVPT201_Syllabus.html#class-communication",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Class Communication",
    "text": "Class Communication\nPlease do not contact me through ELMS. ELMS messages will probably reach me eventually, but it will be slower and less reliable than an email.\nThe first avenue of communication for this course is with your designated teaching assistant. All issues, problems, questions, concerns should first be addressed with them, unless the issue is of a sensitive nature. Please provide documentation, including paperwork for student disability services, and notice of absence to your TA. If issues cannot be resolved, or questions cannot be answered by the TA, then contact me. Please allow TA‚Äôs and/or the professor a least 24 hours to respond to emails (48 to 72 hours on weekends).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#extra-credit",
    "href": "GVPT201_Syllabus.html#extra-credit",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Extra credit",
    "text": "Extra credit\nGraded assignments in the class provide students with ample opportunity to demonstrate mastery of the materials. The assigned material is appropriate in scope for completion within a single semester. Therefore, no extra credit will be offered.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#grade-challenges",
    "href": "GVPT201_Syllabus.html#grade-challenges",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Grade Challenges",
    "text": "Grade Challenges\nAny challenges to a grade must be submitted in writing no sooner than one week after the assignment has been graded. All challenges must be submitted to the section teaching assistant first.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "GVPT201_Syllabus.html#code-of-conduct",
    "href": "GVPT201_Syllabus.html#code-of-conduct",
    "title": "GVPT 201: Scope and Methods for Political Science Research Spring 2025",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nIt is assumed that all students are familiar with and adhere to the code of academic integrity.\nFor University policies including regarding attendance, absences, missed assignments, grade complaints, etc. see this page.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "Slides/slides_01.html#research-questions",
    "href": "Slides/slides_01.html#research-questions",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Research Questions",
    "text": "Research Questions\n\nDoes religion play a role in civil wars?\nWhat causes increasing income inequality in least developed countries?\nWhy has public opinion on same sex marriage liberalized so rapidly?\nIs the U.S. becoming more polarized?\n\n\nNot everyone is going to agree on what these terms mean!\n\n\nBefore we can get anywhere researching these questions, we need to define the thing we‚Äôre studying"
  },
  {
    "objectID": "Slides/slides_01.html#defining-things-harder-than-it-seems",
    "href": "Slides/slides_01.html#defining-things-harder-than-it-seems",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Defining things: harder than it seems!",
    "text": "Defining things: harder than it seems!\n\n\n\nReasonable definition of a chair\n\n\n\n\n\n\nChair"
  },
  {
    "objectID": "Slides/slides_01.html#terms",
    "href": "Slides/slides_01.html#terms",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Terms",
    "text": "Terms\n\nConceptual Definition\n\nA description of the concrete, measurable properties of a concept and the unit of analysis to which it applies\n\nUnit of Analysis\n\nThe entity that that is being studied. For instance: individuals, governments, parties etc.\n\nOperational Definition\n\nA description of the instrument used to measure the concept"
  },
  {
    "objectID": "Slides/slides_01.html#crafting-conceptual-definitions-unit-of-analysis",
    "href": "Slides/slides_01.html#crafting-conceptual-definitions-unit-of-analysis",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Crafting Conceptual Definitions: Unit of Analysis",
    "text": "Crafting Conceptual Definitions: Unit of Analysis\n\nWhat is the unit? What entity possesses the characteristic?\n\nThe U.S. and Canada are democracies (concept: democracy, unit: countries)\nLincoln, LBJ, and Trump are the three tallest U.S. presidents (concept: height, unit: presidents/people)\nLabour is the UK‚Äôs main center-left political party (concept: party ideology/family, unit: political party)\n\n\n\nOne way to think of this: if you put your data into a spreadsheet, what does each ‚Äúrow‚Äù represent? The answer to that question is the unit of analysis."
  },
  {
    "objectID": "Slides/slides_01.html#unit-of-analysis-and-the-ecological-fallacy",
    "href": "Slides/slides_01.html#unit-of-analysis-and-the-ecological-fallacy",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Unit of analysis and the ecological fallacy",
    "text": "Unit of analysis and the ecological fallacy\nThe ecological fallacy occurs when you attribute a characteristic of groups to individuals. For instance:\n\nHigh-income states tend to vote for Democrats, but rich people tend to vote for Republicans.\nSuicide rates in 19th century Europe were higher in Protestant countries compared to Catholic countries, but Protestant individuals were no more likely to die by suicide.\nIn the 1930 census, zip codes with more immigrants had higher literacy rates, but immigrant individuals had lower literacy rates.\n\nAll of these are fundamentally problems of ignoring the unit of analysis."
  },
  {
    "objectID": "Slides/slides_01.html#crafting-conceptual-definitions-key-features",
    "href": "Slides/slides_01.html#crafting-conceptual-definitions-key-features",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Crafting Conceptual Definitions: Key features",
    "text": "Crafting Conceptual Definitions: Key features\n\nWhat are the essential features of the concept?\n\nIf there are cases or definitions everyone agrees on, what characteristics do they share?\nAre certain qualities necessary or sufficient for a case to belong to a category?\nWhat characteristics are most distinctive to those cases?\nWhat is most helpful for clarifying edge-cases?\n\nAre there multiple dimensions or just one? If two characteristics always occur together, you might only need to account for one of them!"
  },
  {
    "objectID": "Slides/slides_01.html#crafting-conceptual-definitions-transparency",
    "href": "Slides/slides_01.html#crafting-conceptual-definitions-transparency",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Crafting Conceptual Definitions: transparency",
    "text": "Crafting Conceptual Definitions: transparency\nWe want to avoid being Potter Stewart:\n\nThe goal is cumulative knowledge, and a private definition can‚Äôt provide that."
  },
  {
    "objectID": "Slides/slides_01.html#some-steps-to-take",
    "href": "Slides/slides_01.html#some-steps-to-take",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Some steps to take:",
    "text": "Some steps to take:\n\n\nIdentify the unit of analysis\nMake a list of important properties, clear examples and non-examples, and/or generally accepted definitions\nRemove items that aren‚Äôt measurable\nReduce dimensions where possible (if a characteristic is shared by positive cases and negative cases, then it isn‚Äôt useful)\nRefine as needed"
  },
  {
    "objectID": "Slides/slides_01.html#conceptualizing-democracy",
    "href": "Slides/slides_01.html#conceptualizing-democracy",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Conceptualizing Democracy",
    "text": "Conceptualizing Democracy\nSome proposed features:\n\n\nRegular elections with meaningful alternatives\nPeaceful transfer of power\nFree expression\nA competitive media environment\nAutonomous political groups\nRule of law\nChecks and balances\nProperty rights"
  },
  {
    "objectID": "Slides/slides_01.html#conceptualizing-democracy-1",
    "href": "Slides/slides_01.html#conceptualizing-democracy-1",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Conceptualizing Democracy",
    "text": "Conceptualizing Democracy\nUnit of analysis: governments (usually national governments)\n\n\nCase:\n\nDefinitely democracies: U.S., Uruguay, Taiwan, Japan, Botswana\nDefinitely autocracies: North Korea, Saudi Arabia, Russia\nEdge cases: Hungary, Turkey, Tunisia\n\n\nFeatures:\n\nVoting and elections\nMultiple parties\nMeaningful civil liberties\nStability and monopoly on violence\n\n\n\nThis may need refinement: what about sham elections?\nThis may not be distinctive: there are stable autocracies on the list"
  },
  {
    "objectID": "Slides/slides_01.html#operationalization",
    "href": "Slides/slides_01.html#operationalization",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Operationalization",
    "text": "Operationalization\nEven where we agree on a definition, we will need to measure a concept and there is often slippage here"
  },
  {
    "objectID": "Slides/slides_01.html#considerations-reliability",
    "href": "Slides/slides_01.html#considerations-reliability",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Considerations: Reliability",
    "text": "Considerations: Reliability\nReliability refers to how consistently the same measurement instrument produces the same result"
  },
  {
    "objectID": "Slides/slides_01.html#considerations-validity",
    "href": "Slides/slides_01.html#considerations-validity",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Considerations: Validity",
    "text": "Considerations: Validity\n\nValidity refers to whether an operational definition correctly measures the concept we‚Äôre interested in.\nA challenge to validity might come from cases that seem mis-categorized in our definition. For example: the minimalist definition of democracy suggests that Japan was authoritarian for much of the latter half of the 20th century."
  },
  {
    "objectID": "Slides/slides_01.html#considerations-validity-and-reliability",
    "href": "Slides/slides_01.html#considerations-validity-and-reliability",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Considerations: Validity and Reliability",
    "text": "Considerations: Validity and Reliability\n\nMeasures could be reliable but invalid: your astrological sign is a reliable measure of your political views because it doesn‚Äôt change, but it also isn‚Äôt valid because it has no real correspondence to your actual politics.\nMeasures could be valid but unreliable: an exam with a single well-written question might be a valid measure of a student‚Äôs understanding of material, but it will probably have more random variability compared to an exam with multiple poorly-written questions."
  },
  {
    "objectID": "Slides/slides_01.html#measurement-error-1",
    "href": "Slides/slides_01.html#measurement-error-1",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Measurement Error",
    "text": "Measurement Error\n\nMeasurement error is a source of noise, systematic measurement error is a source of bias\nWe‚Äôll generally find that random noise is much easier to deal with than bias because we can simply collect more data. Significant bias, on the other hand, presents profound challenges to research because we can only correct it if we can measure it"
  },
  {
    "objectID": "Slides/slides_01.html#party-id",
    "href": "Slides/slides_01.html#party-id",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Party ID",
    "text": "Party ID\n\nSources like the American National Election Study rely on self-description to measure party ID, but each respondent receives two questions instead of one."
  },
  {
    "objectID": "Slides/slides_01.html#party-id-1",
    "href": "Slides/slides_01.html#party-id-1",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Party ID",
    "text": "Party ID\nRoughly a third of the electorate describe themselves as ‚Äúindependent‚Äù"
  },
  {
    "objectID": "Slides/slides_01.html#party-id-2",
    "href": "Slides/slides_01.html#party-id-2",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Party ID",
    "text": "Party ID\nWhen pressed, many independents will say they lean toward a party."
  },
  {
    "objectID": "Slides/slides_01.html#party-id-3",
    "href": "Slides/slides_01.html#party-id-3",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Party ID",
    "text": "Party ID\n\n\n\nBased on voting behavior, ‚Äúleaners‚Äù are more similar to partisans.\nSo we commonly measure party ID with two questions."
  },
  {
    "objectID": "Slides/slides_02.html#concepts-and-variables",
    "href": "Slides/slides_02.html#concepts-and-variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Concepts and variables",
    "text": "Concepts and variables\n\nDefinition: identifying concrete features of the objects or events we‚Äôre studying and the tools to measure them.\nMeasurement representing real-life objects and events as variables\nDescription making generalizations about variables"
  },
  {
    "objectID": "Slides/slides_02.html#variables",
    "href": "Slides/slides_02.html#variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Variables",
    "text": "Variables\n\nThe results of the measurement process.\nBy definition a variable must vary\nHow we describe a variable will depend on how we measure it."
  },
  {
    "objectID": "Slides/slides_02.html#nominal-variables",
    "href": "Slides/slides_02.html#nominal-variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Nominal Variables",
    "text": "Nominal Variables\n\n\nNominal variables are categorical variables with no intrinsic ordering.\nExamples include the names of countries or people, someone‚Äôs religion or racial/ethnic self id\nSome nominal variables are represented by numbers, but the values of those numbers are arbitrary: zip codes, jersey numbers, and telephone numbers are still nominal because there‚Äôs no ordering to them."
  },
  {
    "objectID": "Slides/slides_02.html#nominal-variables-1",
    "href": "Slides/slides_02.html#nominal-variables-1",
    "title": "Chapter 2: Measurement and Description",
    "section": "Nominal Variables",
    "text": "Nominal Variables\nThe region of a particular U.S. state is a nominal variable: there‚Äôs a fixed number of categories and no intrinsic ordering"
  },
  {
    "objectID": "Slides/slides_02.html#ordinal-variables",
    "href": "Slides/slides_02.html#ordinal-variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Ordinal Variables",
    "text": "Ordinal Variables\n\n\n\nOrdinal variables have a small number of categories that can be ordered.\nHowever, the gaps between differing ranks may be unequal.\n\n\nTop finishing times for Boston Marathon in 2024. The placements are ordinal: the distance in time between first and second place doesn‚Äôt necessarily equal the distance between second and third."
  },
  {
    "objectID": "Slides/slides_02.html#ordinal-variables-1",
    "href": "Slides/slides_02.html#ordinal-variables-1",
    "title": "Chapter 2: Measurement and Description",
    "section": "Ordinal Variables",
    "text": "Ordinal Variables\nA common source of ordinal variables will be survey items that ask people to rate their position on a scale from ‚Äústrongly agree‚Äù to ‚Äústrongly disagree‚Äù or ‚Äúvery important‚Äù to ‚Äúnot at all important‚Äù."
  },
  {
    "objectID": "Slides/slides_02.html#ordinal-variables-2",
    "href": "Slides/slides_02.html#ordinal-variables-2",
    "title": "Chapter 2: Measurement and Description",
    "section": "Ordinal Variables",
    "text": "Ordinal Variables\nAnother source of ordinal variables might be data that we‚Äôve grouped into ordered categories based on another variable."
  },
  {
    "objectID": "Slides/slides_02.html#ordinal-variables-3",
    "href": "Slides/slides_02.html#ordinal-variables-3",
    "title": "Chapter 2: Measurement and Description",
    "section": "Ordinal Variables",
    "text": "Ordinal Variables\n\n\nFor instance: the World Bank classifies countries into four ordinal categories based on their per-capita GDP. There‚Äôs a clear ordering, but the spaces are not equal."
  },
  {
    "objectID": "Slides/slides_02.html#ordinal-variables-4",
    "href": "Slides/slides_02.html#ordinal-variables-4",
    "title": "Chapter 2: Measurement and Description",
    "section": "Ordinal Variables",
    "text": "Ordinal Variables\nTwo things to keep in mind when working with ordinal variables:\n\n\n\n\n\nThe ‚Äúordering‚Äù might be partly a function of your research question. You could flip these or combine categories to arrange them from ‚Äúmost partisan‚Äù to ‚Äúleast partisan‚Äù.\nSome survey variables may only be ordinal after you remove all the people who gave ‚Äúdon‚Äôt know‚Äù responses."
  },
  {
    "objectID": "Slides/slides_02.html#interval-variables",
    "href": "Slides/slides_02.html#interval-variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Interval Variables",
    "text": "Interval Variables\n\nThese are just numbers. They‚Äôre measured along a continuum with equal spacing (i.e., the difference from 3 and 4 is ‚Äúthe same‚Äù as the difference between 6 and 7)\nExamples: age, height, temperature, distance."
  },
  {
    "objectID": "Slides/slides_02.html#interval-variables-1",
    "href": "Slides/slides_02.html#interval-variables-1",
    "title": "Chapter 2: Measurement and Description",
    "section": "Interval Variables",
    "text": "Interval Variables\n‚ÄúTrue‚Äù interval variables are less common in survey research, but we‚Äôll often treat ordinal variables as ‚Äúmore-or-less interval‚Äù if they a lot (7+) categories\n\nStrictly speaking these ‚Äúfeeling thermometer‚Äù responses are more like ordinal variables. But they‚Äôre close enough for us to treat them like interval variables for most purposes."
  },
  {
    "objectID": "Slides/slides_02.html#dichotomousdummy-variables",
    "href": "Slides/slides_02.html#dichotomousdummy-variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Dichotomous/Dummy Variables",
    "text": "Dichotomous/Dummy Variables\n\nDichotomous variables that take on only two values: TRUE/FALSE, or Republican/Democrat, War/Peace etc.\n‚ÄúDummy‚Äù variables will encode this dichotomy as 0s and 1s, which can simplify some math operations\n\nMost importantly: the mean of a dummy variable = the proportion of 1s in the data!\n\n\n\n\ndummy_vector &lt;- c(1,1,1,1,0,0,0,0,0,0)\n\nmean(dummy_vector)\n\n[1] 0.4"
  },
  {
    "objectID": "Slides/slides_02.html#dichotomousdummy",
    "href": "Slides/slides_02.html#dichotomousdummy",
    "title": "Chapter 2: Measurement and Description",
    "section": "Dichotomous/Dummy",
    "text": "Dichotomous/Dummy\nDummy coding is important for statistical modeling because how we can make nominal data into meaningful numeric data:\n\n\n\n\n\n\nWho did you vote for in 2020?\nTrump\nBiden\nStein\n\n\n\n\nTrump\n1\n0\n0\n\n\nBiden\n0\n1\n0\n\n\nJill Stein\n0\n0\n1"
  },
  {
    "objectID": "Slides/slides_02.html#index-variables",
    "href": "Slides/slides_02.html#index-variables",
    "title": "Chapter 2: Measurement and Description",
    "section": "Index variables",
    "text": "Index variables\nSome surveys may measure an attitude by asking multiple questions on the same topic and then aggregating those responses. These aggregate indexes are often treated as interval-level variables."
  },
  {
    "objectID": "Slides/slides_02.html#index-variables-1",
    "href": "Slides/slides_02.html#index-variables-1",
    "title": "Chapter 2: Measurement and Description",
    "section": "Index variables",
    "text": "Index variables\n\n\nThe values highlighted in red indicate more ‚Äúauthoritarian‚Äù attitudes toward child rearing.\n\n\n\n\n\n\nquestion\nvalue\npercent\n\n\n\n\nConsiderate vs. Well-behaved\nBeing considerate\n72%\n\n\nWell behaved\n28%\n\n\nCuriosity vs. Good Manners\nCuriosity\n39%\n\n\nGood manners\n61%\n\n\nSelf Reliance vs. Obedience\nObedience\n44%\n\n\nSelf-reliance\n56%\n\n\nIndependence vs. Respect for Elders\nIndependence\n31%\n\n\nRespect for elders\n69%\n\n\n\n\n\n\n\n\n\nThe ‚Äúauthoritarianism‚Äù column is an index variable created by counting the number of ‚Äúauthoritarian‚Äù answers to a single question.\n\n\n\n\n\n\nauthoritarianism\npercent\ncumulative %\n\n\n\n\n0\n18.3%\n18.3%\n\n\n1\n17.7%\n36.0%\n\n\n2\n23.2%\n59.2%\n\n\n3\n25.1%\n84.2%\n\n\n4\n15.8%\n100.0%"
  },
  {
    "objectID": "Slides/slides_02.html#multiple-levels-of-measurement",
    "href": "Slides/slides_02.html#multiple-levels-of-measurement",
    "title": "Chapter 2: Measurement and Description",
    "section": "Multiple levels of measurement",
    "text": "Multiple levels of measurement\nIt‚Äôs often possible to measure the same variable at multiple levels of measurement.\n‚ÄúEducation‚Äù, for instance, could be recorded as interval, ordinal, or dichotomous:\n\n\n\n\n\n\n\n\nYears of schooling\nHighest Level of Schooling Completed\nSome College\n\n\n\n\n9\nLess than High School\nNo\n\n\n10\nLess than High School\nNo\n\n\n12\nHigh School\nNo\n\n\n13\nSome College\nYes\n\n\n14\nSome College\nYes\n\n\n15\nSome College\nYes\n\n\n16\nBachelor‚Äôs\nYes\n\n\n17\nPost Bachelor‚Äôs\nYes"
  },
  {
    "objectID": "Slides/slides_02.html#multiple-levels-of-measurement-1",
    "href": "Slides/slides_02.html#multiple-levels-of-measurement-1",
    "title": "Chapter 2: Measurement and Description",
    "section": "Multiple levels of measurement",
    "text": "Multiple levels of measurement\nIt‚Äôs often preferable to use the highest level of precision available, but sometimes we choose a less precise measure because its more parsimonious, less ‚Äúnoisy‚Äù, or easier to display in a table or graph."
  },
  {
    "objectID": "Slides/slides_02.html#multiple-levels-of-measurement-2",
    "href": "Slides/slides_02.html#multiple-levels-of-measurement-2",
    "title": "Chapter 2: Measurement and Description",
    "section": "Multiple levels of measurement",
    "text": "Multiple levels of measurement\nFor example: many analyses of Trump supporters will collapse education into college vs.¬†non-college because (at least for whites) there‚Äôs a clear division between college grads and non-college grads:"
  },
  {
    "objectID": "Slides/slides_02.html#unit-of-analysis-and-levels-of-measurement",
    "href": "Slides/slides_02.html#unit-of-analysis-and-levels-of-measurement",
    "title": "Chapter 2: Measurement and Description",
    "section": "Unit of analysis and levels of measurement",
    "text": "Unit of analysis and levels of measurement\nKeep in mind that aggregation changes the unit of analysis. ‚ÄúDid you vote for Trump in 2020?‚Äù is dichotomous, but Trump‚Äôs share of the vote across an entire state is continuous:"
  },
  {
    "objectID": "Slides/slides_04.html#cross-tabulation-step-1",
    "href": "Slides/slides_04.html#cross-tabulation-step-1",
    "title": "Chapter 4: Research Design",
    "section": "Cross tabulation: Step 1",
    "text": "Cross tabulation: Step 1\nStart by calculating the number of observations with each value of each category:\n\n\n\n\n\n\n\n\niv\ndv\n\n\n\n\nHIGH\nNo\n\n\nHIGH\nNo\n\n\nLOW\nNo\n\n\nHIGH\nYes\n\n\nHIGH\nYes\n\n\nHIGH\nYes\n\n\nHIGH\nYes\n\n\nLOW\nYes\n\n\nLOW\nYes\n\n\nLOW\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1\n2\n\n\nYes\n3\n4\n\n\n\n\n\nTotal\n4\n6"
  },
  {
    "objectID": "Slides/slides_04.html#cross-tabulation-step-2",
    "href": "Slides/slides_04.html#cross-tabulation-step-2",
    "title": "Chapter 4: Research Design",
    "section": "Cross tabulation: Step 2",
    "text": "Cross tabulation: Step 2\nThen, calculate the proportion/percentage of observations among each value of the IV.\nIf the independent variable is in the columns, then the columns should sum to 100%.\nIf the independent variable is in the rows, then the rows should sum to 100%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1\n2\n\n\nYes\n3\n4\n\n\n\n\n\nTotal\n4\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1 (25%)\n2 (33%)\n\n\nYes\n3 (75%)\n4 (67%)\n\n\n\n\n\nTotal\n4\n6"
  },
  {
    "objectID": "Slides/slides_04.html#cross-tabulation-interpretation",
    "href": "Slides/slides_04.html#cross-tabulation-interpretation",
    "title": "Chapter 4: Research Design",
    "section": "Cross tabulation: interpretation",
    "text": "Cross tabulation: interpretation\nLook at what happens to the DV at different values of the IV. If your variables are ordinal, you should be able to identify a direction of the effect.\nThe proportion of ‚ÄúYes‚Äù values decreases as the IV goes from lower to higher, so this is a negative or inverse relationship.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv\n\n\n\ndv\nLOW\nHIGH\n\n\n\n\nNo\n1 (25%)\n2 (33%)\n\n\nYes\n3 (75%)\n4 (67%)\n\n\n\n\n\nTotal\n4\n6\n\n\n\n\n\n\n\n\n\nUsing a bar graph or line graph can make these relationships easier to spot:"
  },
  {
    "objectID": "Slides/slides_04.html#cross-tabulation-notes",
    "href": "Slides/slides_04.html#cross-tabulation-notes",
    "title": "Chapter 4: Research Design",
    "section": "Cross tabulation: notes",
    "text": "Cross tabulation: notes\n\nKey rule: always calculate percentages or proportions by categories of the independent variable.\n\nThis allows you to compare groups that are different sizes.\n\nIf one or both variables are interval-level, you can bin them in order to use them in a cross tab. For instance, you could separate an interval like into a series of age ranges."
  },
  {
    "objectID": "Slides/slides_04.html#cross-tabulation-example",
    "href": "Slides/slides_04.html#cross-tabulation-example",
    "title": "Chapter 4: Research Design",
    "section": "Cross tabulation: example",
    "text": "Cross tabulation: example\nHypothesis: in a comparison of individuals, independents are less likely to turn out to vote compared to people who support one party or another.\n\nHow should I calculate proportions here?\n\n\n\n\nVoter Turnout in 2020 by party ID\n\n\n\n\n\n\n\n\n\n\nParty ID\n\n\n\nturnout2020\nDemocrat\nIndependent\nRepublican\n\n\n\n\n0. Did not vote\n335\n316\n382\n\n\n1. Voted\n3160\n560\n2714"
  },
  {
    "objectID": "Slides/slides_04.html#cross-tabulation-example-1",
    "href": "Slides/slides_04.html#cross-tabulation-example-1",
    "title": "Chapter 4: Research Design",
    "section": "Cross tabulation: example",
    "text": "Cross tabulation: example\nAre these results generally consistent with my hypothesis?\n\n\n\n\n\n\nVoter Turnout in 2020 by party ID\n\n\n\n\n\n\n\n\n\n\nParty ID\n\n\n\nturnout2020\nDemocrat\nIndependent\nRepublican\n\n\n\n\n0. Did not vote\n335 (10%)\n316 (36%)\n382 (12%)\n\n\n1. Voted\n3160 (90%)\n560 (64%)\n2714 (88%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we think of party ID as an ordered variable, this is a curvilinear relationship."
  },
  {
    "objectID": "Slides/slides_04.html#rowcolumn-percentages",
    "href": "Slides/slides_04.html#rowcolumn-percentages",
    "title": "Chapter 4: Research Design",
    "section": "Row/Column percentages",
    "text": "Row/Column percentages\nWhat happens if I calculate % among the values of the DV?\nHere‚Äôs the relationship between education and voter turnout with % calculated on education level:\n\n\n\n\nVoter Turnout in 2020 by highest level of education completed\n\n\n\n\n\n\n\n\n\n\n\n\nEducation\n\n\n\nturnout2020\n1. Less than high school credential\n2. High school credential\n3. Some post-high school, no bachelor's degree\n4. Bachelor's degree\n5. Graduate degree\n\n\n\n\n0. Did not vote\n130 (41%)\n286 (24%)\n380 (15%)\n135 (7%)\n91 (6%)\n\n\n1. Voted\n185 (59%)\n883 (76%)\n2148 (85%)\n1749 (93%)\n1388 (94%)\n\n\n\nNote: \n\n\n\n\n\n\n\n Column % in parentheses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe results suggest a positive or direct relationship: as education increases, so does the % turnout."
  },
  {
    "objectID": "Slides/slides_04.html#rowcolumn-percentages-1",
    "href": "Slides/slides_04.html#rowcolumn-percentages-1",
    "title": "Chapter 4: Research Design",
    "section": "Row/Column percentages",
    "text": "Row/Column percentages\nWhat happens if I calculate % among the values of the DV?\nHere‚Äôs the relationship between education and voter turnout with % calculated across voter turnout\n\n\n\n\nVoter Turnout in 2020 by highest level of education completed\n\n\n\n\n\n\n\n\n\n\n\n\nEducation\n\n\n\nturnout2020\n1. Less than high school credential\n2. High school credential\n3. Some post-high school, no bachelor's degree\n4. Bachelor's degree\n5. Graduate degree\n\n\n\n\n0. Did not vote\n130 (13%)\n286 (28%)\n380 (37%)\n135 (13%)\n91 (9%)\n\n\n1. Voted\n185 (3%)\n883 (14%)\n2148 (34%)\n1749 (28%)\n1388 (22%)\n\n\n\nNote: \n\n\n\n\n\n\n\n Row % in parentheses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, the results can give the misleading impression that there‚Äôs a curvilinear relationship: turnout drops off for Bachelor‚Äôs Degrees and above."
  },
  {
    "objectID": "Slides/slides_04.html#rowcolumn-percentages-2",
    "href": "Slides/slides_04.html#rowcolumn-percentages-2",
    "title": "Chapter 4: Research Design",
    "section": "Row/Column percentages",
    "text": "Row/Column percentages\nEither of these tables might be a valid way to look at these data, but they answer slightly different questions:\n\n\nIf I want to compare turnout at different levels of education, then I need to calculate % turnout among people with different levels of education.\nIf I want to compare education among voters and non-voters, then I need to calculate % education among people who voted and didn‚Äôt vote.\nWhich variable is the IV or DV is sometimes a theoretical question, but in this case its unlikely that voting is causing people to become more educated, so it probably doesn‚Äôt make sense to calculate percentages by voting vs.¬†non-voting."
  },
  {
    "objectID": "Slides/slides_04.html#mean-comparison-1",
    "href": "Slides/slides_04.html#mean-comparison-1",
    "title": "Chapter 4: Research Design",
    "section": "Mean Comparison",
    "text": "Mean Comparison\nGDP data has been grouped into five categories, so now I just need to calculate the average of CO2 emissions within each group of the ordinal IV:\n\n\n\n\nGDP Per capita range\nCO2 emissions per capita\n\n\n\n\n1. $3k or less\n0.3128312\n\n\n2. $3k to $10k\n1.2680574\n\n\n3. $10k to $25k\n4.4065669\n\n\n4. $25k to $45k\n8.0307610\n\n\n5. $45k or more\n12.3134306\n\n\n\n\n\n\n\nIs this generally consistent with expectations?"
  },
  {
    "objectID": "Slides/slides_04.html#mean-comparison-2",
    "href": "Slides/slides_04.html#mean-comparison-2",
    "title": "Chapter 4: Research Design",
    "section": "Mean Comparison",
    "text": "Mean Comparison\nHere again, the relationship can be easier to conceptualize if we plot it."
  },
  {
    "objectID": "Slides/slides_04.html#curvilinear-relationships",
    "href": "Slides/slides_04.html#curvilinear-relationships",
    "title": "Chapter 4: Research Design",
    "section": "Curvilinear Relationships",
    "text": "Curvilinear Relationships\nA relationship like this will rarely be perfectly straight, so ‚Äúlinearity‚Äù and ‚Äúcurvilinearity‚Äù are partly a matter of degree, but there are some cases where there is a clear ‚ÄúU‚Äù shape to the relationship:\n\n\n\n\n\n\niv\ndv\n\n\n\n\n1. Extremely liberal\n6.314\n\n\n2. Liberal\n5.685\n\n\n3. Slightly liberal\n5.001\n\n\n4. Moderate; middle of the road\n4.651\n\n\n5. Slightly conservative\n4.636\n\n\n6. Conservative\n4.974\n\n\n7. Extremely conservative\n5.363"
  },
  {
    "objectID": "Slides/slides_04.html#rival-explanations",
    "href": "Slides/slides_04.html#rival-explanations",
    "title": "Chapter 4: Research Design",
    "section": "Rival Explanations",
    "text": "Rival Explanations\n\nHow can we distinguish correlation from causation?\nThis process inevitably requires us to consider rival explanations for an observed relationship:\n\nFor instance: if I find that social media use correlated with a lower likelihood of turning out to vote, I might ask whether age is a confounder that could explain this correlation."
  },
  {
    "objectID": "Slides/slides_04.html#confounding",
    "href": "Slides/slides_04.html#confounding",
    "title": "Chapter 4: Research Design",
    "section": "Confounding",
    "text": "Confounding\nWhat I want to show is that Fox News viewership is cases a decreased chance of getting a Covid vaccine.\n\n\n\n\n\n\n\nmrdag\n\n\n\nX\n\nFox News\n\n\n\nY\n\nCovid Vaccine\n\n\n\nX-&gt;Y"
  },
  {
    "objectID": "Slides/slides_04.html#confounding-1",
    "href": "Slides/slides_04.html#confounding-1",
    "title": "Chapter 4: Research Design",
    "section": "Confounding",
    "text": "Confounding\nThere‚Äôs a correlation, but I‚Äôm concerned this relationship is spurious because I know that things like existing political views are already correlated with media consumption, and those might explain any correlation I see here:\n\n\n\n\n\n\n\nmrdag\n\n\n\nZ\n\nConservatism\n\n\n\nX\n\nFox News\n\n\n\nZ-&gt;X\n\n\n\n\n\nY\n\nCovid Vaccine\n\n\n\nZ-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\nIts possible that this difference in ideology accounts for the entire observed correlation between media habits and vaccines. I can‚Äôt really rule this possibility out without further investigation."
  },
  {
    "objectID": "Slides/slides_04.html#confounding-2",
    "href": "Slides/slides_04.html#confounding-2",
    "title": "Chapter 4: Research Design",
    "section": "Confounding",
    "text": "Confounding\nWhat if I could randomly assign people to watch Fox News? Random assignment would ensure that nothing is correlated with Fox news viewership.\n\n\n\n\n\n\n\nmrdag\n\n\n\nZ\n\nConservatism\n\n\n\nY\n\nCovid Vaccine\n\n\n\nZ-&gt;Y\n\n\n\n\n\nX\n\nFox News\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\nIdeology may still matter for getting a vaccine, but since if conservatism is randomly distributed between social media users and non-users, it no longer confounds the observed relationship."
  },
  {
    "objectID": "Slides/slides_04.html#experiments-1",
    "href": "Slides/slides_04.html#experiments-1",
    "title": "Chapter 4: Research Design",
    "section": "Experiments",
    "text": "Experiments\n\n\nExperiments are considered a ‚Äúgold standard‚Äù because they can account for all kinds of confounding, including confounding caused by unobserved or unexpected relationships.\nHowever, they have two key limitations:\n\nExternal validity: results in the lab may not easily translate to results in real life.\nFeasibility: many interesting questions just can‚Äôt be randomly assigned. We can assign ‚Äúdemocracy‚Äù or ‚Äúwar‚Äù or ‚Äúreligion‚Äù to people."
  },
  {
    "objectID": "Slides/slides_04.html#experiments-field-experiments",
    "href": "Slides/slides_04.html#experiments-field-experiments",
    "title": "Chapter 4: Research Design",
    "section": "Experiments: Field Experiments",
    "text": "Experiments: Field Experiments\nField experiments can lessen the external validity problem by using random assignment in the field.\n\nFor instance, one common way to study GOTV messaging is to randomly select households to receive mailers:\n\n\n Civic duty treatment\n Hawthorne treatment\n\n Neighbors treatment  Self treatment\n\n\n\n\nFrom: GERBER, A. S., GREEN, D. P., & LARIMER, C. W. (2008). Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment. American Political Science Review, 102(1), 33‚Äì48. doi:10.1017/S000305540808009X"
  },
  {
    "objectID": "Slides/slides_04.html#experiments-field-experiments-1",
    "href": "Slides/slides_04.html#experiments-field-experiments-1",
    "title": "Chapter 4: Research Design",
    "section": "Experiments: Field Experiments",
    "text": "Experiments: Field Experiments\n\nFrom: GERBER, A. S., GREEN, D. P., & LARIMER, C. W. (2008). Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment. American Political Science Review, 102(1), 33‚Äì48. doi:10.1017/S000305540808009X"
  },
  {
    "objectID": "Slides/slides_04.html#experiments-natural-experiments",
    "href": "Slides/slides_04.html#experiments-natural-experiments",
    "title": "Chapter 4: Research Design",
    "section": "Experiments: Natural Experiments",
    "text": "Experiments: Natural Experiments\nField experiments can face fewer external validity problems, but some things still can‚Äôt be experimentally manipulated.\nNatural experiments use ‚Äúquasi‚Äù randomization or ‚Äúrandomization by nature‚Äù where treatments are assigned more-or-less randomly."
  },
  {
    "objectID": "Slides/slides_04.html#experiments-natural-experiments-1",
    "href": "Slides/slides_04.html#experiments-natural-experiments-1",
    "title": "Chapter 4: Research Design",
    "section": "Experiments: Natural Experiments",
    "text": "Experiments: Natural Experiments\n\n\n\nViewing Fox News isn‚Äôt random, but areas where Fox News is lower in the channel order will have more viewers.\nChannel order is essentially randomly assigned.\nSo, using channel order as a ‚Äútreatment‚Äù assignment might theoretically allow us to account for confounding in an observational setting."
  },
  {
    "objectID": "Slides/slides_04.html#experiments-natural-experiments-2",
    "href": "Slides/slides_04.html#experiments-natural-experiments-2",
    "title": "Chapter 4: Research Design",
    "section": "Experiments: Natural Experiments",
    "text": "Experiments: Natural Experiments\nOther sources of quasi randomization include:\n\n\nLotteries (like the Vietnam Draft, or the literal lottery)\nArbitrary cutoffs (barely winning an election vs.¬†barely losing)\nNatural disasters and weather events\n\n\n\nStill, natural experiments require a mixture of creativity and luck. They‚Äôre not available for most questions."
  },
  {
    "objectID": "Slides/slides_04.html#observational-research-and-sampling",
    "href": "Slides/slides_04.html#observational-research-and-sampling",
    "title": "Chapter 4: Research Design",
    "section": "Observational Research and sampling",
    "text": "Observational Research and sampling\n\n\nThis category includes qualitative methods, but we‚Äôre focusing mostly on quantitative (large-N) methods.\nIn quantitative studies of countries or states, we might not worry much about questions of ‚Äúrepresentativeness‚Äù because we can collect data on all of the countries or states.\nBut in quantitative research on people, its typically not feasible to study everyone. We‚Äôll need to sample and then make generalizations."
  },
  {
    "objectID": "Slides/slides_04.html#observational-research-survey-vs.-census",
    "href": "Slides/slides_04.html#observational-research-survey-vs.-census",
    "title": "Chapter 4: Research Design",
    "section": "Observational Research: Survey vs.¬†Census",
    "text": "Observational Research: Survey vs.¬†Census\n\nA true population census means studying everyone, or nearly everyone. This is rarely feasible except with a lot of resources!\nSurvey research aims to find a representative sample of the population and then make inferences about the population.\n\nRepresentativeness a central concern here. If our samples aren‚Äôt representative, then they can‚Äôt be generalized to the population.\nThe use of surveys introduces problems of statistical inference and uncertainty. There is a chance that a random sample will be biased (just like a coin can land on tails 5 times in a row), but that risk is quantifiable and it becomes extremely small when we have a lot of observations.\nI might not be able to tell you the exact % of the public approves of congress, but I can tell you the probability of being off by 20 percentage points in a 1,000 person survey."
  },
  {
    "objectID": "Slides/slides_04.html#the-1936-literary-digest-poll",
    "href": "Slides/slides_04.html#the-1936-literary-digest-poll",
    "title": "Chapter 4: Research Design",
    "section": "The 1936 Literary Digest Poll",
    "text": "The 1936 Literary Digest Poll\n\n\n\n\nLiterary Digest wanted to predict the outcome of the 1936 presidential election.\nMailed out approx. 10 million ‚Äúballots‚Äù based on address data from social clubs, automobile registrations, phone books etc. about 2.4 million were returned.\n10 million much larger than the target for most polls\nA 24% response rate was low for the time, but higher than contemporary polls\nScientific polling was in its infancy, Literary Digest touted their lack of any fancy data manipulation as an advantage over polls that used more complex methodologies."
  },
  {
    "objectID": "Slides/slides_04.html#the-1936-literary-digest-poll-1",
    "href": "Slides/slides_04.html#the-1936-literary-digest-poll-1",
    "title": "Chapter 4: Research Design",
    "section": "The 1936 Literary Digest poll",
    "text": "The 1936 Literary Digest poll\n\n\n\n\n\nPrediction for Landon\nPrediction for Roosevelt\n\n\n54% of the popular vote\n41% of the popular vote"
  },
  {
    "objectID": "Slides/slides_04.html#the-1936-literary-digest-poll-2",
    "href": "Slides/slides_04.html#the-1936-literary-digest-poll-2",
    "title": "Chapter 4: Research Design",
    "section": "The 1936 Literary Digest poll",
    "text": "The 1936 Literary Digest poll\n\n\n\n\n\n\n\n\nNot quite!"
  },
  {
    "objectID": "Slides/slides_04.html#the-1936-literary-digest-poll-3",
    "href": "Slides/slides_04.html#the-1936-literary-digest-poll-3",
    "title": "Chapter 4: Research Design",
    "section": "The 1936 Literary Digest poll",
    "text": "The 1936 Literary Digest poll\n\n\n\n\nContemporaneous analyses attributed the error to sampling bias: Literary Digest targeted car owners and telephone owners, and so the results skewed toward the wealthy\nSubsequent reanalyses point to non-response bias: Roosevelt supporters were systematically less likely to return the postcard compared to Landon supporters.\n\nAnecdotal evidence suggests that this may have been the result of different levels of enthusiasm: Landon voters really didn‚Äôt like Roosevelt and they were motivated to talk about it.\nSample size doesn‚Äôt fix bias! Much smaller random polls can easily outperform a large-yet-biased one.\n\n\n\n\n\n\n\nLusinchi D. ‚ÄúPresident‚Äù Landon and the 1936 Literary Digest Poll: Were Automobile and Telephone Owners to Blame? Social Science History. 2012;36(1):23-54. doi:10.1017/S014555320001035X"
  },
  {
    "objectID": "Slides/slides_04.html#sampling-strategies",
    "href": "Slides/slides_04.html#sampling-strategies",
    "title": "Chapter 4: Research Design",
    "section": "Sampling strategies",
    "text": "Sampling strategies\nA note that‚Äôs still relevant today: non-response bias is a big risk! Some people are more likely to take polls."
  },
  {
    "objectID": "Slides/slides_04.html#sampling-strategies-1",
    "href": "Slides/slides_04.html#sampling-strategies-1",
    "title": "Chapter 4: Research Design",
    "section": "Sampling strategies",
    "text": "Sampling strategies\nContemporary polls often get stuff wrong, but many general election pollsters are able to get a lot closer with far fewer observations (even as conditions get worse!) How?\n\n\n\n\n\nSource: fivethirtyeight.com"
  },
  {
    "objectID": "Slides/slides_06.html#uncertainty-and-sampling",
    "href": "Slides/slides_06.html#uncertainty-and-sampling",
    "title": "Inference",
    "section": "Uncertainty and sampling",
    "text": "Uncertainty and sampling\nThe general intuition:\n\n\nmore data = more certainty. Estimates from a really big representative sample are going to be more likely to approximate the true population mean.\nless variance = more certainty. If people in the target population are pretty much the same, then it is more likely that a given sample will resemble the target population."
  },
  {
    "objectID": "Slides/slides_06.html#margin-of-error",
    "href": "Slides/slides_06.html#margin-of-error",
    "title": "Inference",
    "section": "Margin of error",
    "text": "Margin of error\n\nfrom https://criticalissues.umd.edu/feature/new-study-change-us-public-attitudes-towards-jews-and-muslims-2022-2024"
  },
  {
    "objectID": "Slides/slides_06.html#margin-of-error-1",
    "href": "Slides/slides_06.html#margin-of-error-1",
    "title": "Inference",
    "section": "Margin of error",
    "text": "Margin of error\n\nfrom https://criticalissues.umd.edu/feature/new-study-change-us-public-attitudes-towards-jews-and-muslims-2022-2024"
  },
  {
    "objectID": "Slides/slides_06.html#margin-of-error-2",
    "href": "Slides/slides_06.html#margin-of-error-2",
    "title": "Inference",
    "section": "Margin of error",
    "text": "Margin of error\n\n\nThe margin of error is more frequently called a ‚Äúconfidence interval‚Äù in statistics.\nA confidence interval is a range that we are reasonably certain contains the actual population value.\n\nSpecifically, the margin generally reported in a survey is a 95% confidence interval when there‚Äôs a 50/50 split in a dichotomous outcome.\nIf I estimate that 50% of respondents are Democrats with a margin of error of +/- 3% then I‚Äôm saying I‚Äôm 95% certain that the range 47-53% contains the true population % of Dems."
  },
  {
    "objectID": "Slides/slides_06.html#margin-of-error-confidence-interval",
    "href": "Slides/slides_06.html#margin-of-error-confidence-interval",
    "title": "Inference",
    "section": "Margin of error = Confidence Interval",
    "text": "Margin of error = Confidence Interval\n95% confidence means: ‚Äúif I repeated this survey an infinite number of times and recalculated the CI for each one, 95% of my calculated confidence intervals would contain the actual population value.‚Äù"
  },
  {
    "objectID": "Slides/slides_06.html#margin-of-error-confidence-interval-1",
    "href": "Slides/slides_06.html#margin-of-error-confidence-interval-1",
    "title": "Inference",
    "section": "Margin of error = Confidence Interval",
    "text": "Margin of error = Confidence Interval\n\n\nWe generally aren‚Äôt bothering to sample anything repeatedly, so how do we know this?\n\nThe main reason we‚Äôre able to calculate a confidence interval is because we actually know a lot about how random errors ‚Äúbehave‚Äù in repeated sampling thanks to the central limit theorem."
  },
  {
    "objectID": "Slides/slides_06.html#coin-flips",
    "href": "Slides/slides_06.html#coin-flips",
    "title": "Inference",
    "section": "Coin flips",
    "text": "Coin flips\nThink about flipping a coin:\n\n\nthe probability of landing on heads is 50% (this is our population parameter)\nWe‚Äôll run an ‚Äúexperiment‚Äù where we flip a coin 50 times and calculate the proportion of heads.\n\n(remember that, for a dummy (0, 1) coded dichotomous outcome, the proportion = the mean)"
  },
  {
    "objectID": "Slides/slides_06.html#coin-flips-1",
    "href": "Slides/slides_06.html#coin-flips-1",
    "title": "Inference",
    "section": "Coin flips",
    "text": "Coin flips\nThis is hardly surprising!\n\n# simulating flipping 50 coins: \ncoinflips &lt;- sample(c(\"heads\",\"tails\"), size=50, replace=TRUE)\n# counting the number of heads\nprop_heads&lt;-mean(coinflips=='heads')\n\n\n\nthe proportion of heads is 0.38.\nThe error is .5 - 0.38 = -0.12\n\n\n\nI get closer to the correct answer when I increase the sample size, but I still will have some amount of error:\n\n# simulating flipping 50 coins: \ncoinflips &lt;- sample(c(\"heads\",\"tails\"), size=500, replace=TRUE)\n# counting the number of heads\nprop_heads &lt;- mean(coinflips=='heads')\n\n\n\nthe proportion of heads is 0.51.\nThe error is .5 - 0.51 = 0.01"
  },
  {
    "objectID": "Slides/slides_06.html#the-sampling-distribution-of-coin-flips",
    "href": "Slides/slides_06.html#the-sampling-distribution-of-coin-flips",
    "title": "Inference",
    "section": "The sampling distribution of coin flips",
    "text": "The sampling distribution of coin flips\nRepeating this experiment 5,000 times will give us a sense of the sampling distribution for this sample statistic:\n\n# 5000 \"samples\" of the coin-flipping experiment\ntrials&lt;-replicate(5000, sample(c(\"heads\",\"tails\"), size=50, replace=TRUE)==\"heads\")\n# get the average num of heads in each trial. Expected value = .5\nmean_heads &lt;- colMeans(trials)\n# draw a histogram\nhist(mean_heads, main ='proportion of heads in 50 coin flips', breaks=30)\n\n\nwe should get a distribution that looks like this:"
  },
  {
    "objectID": "Slides/slides_06.html#the-sampling-distribution-of-coin-flips-1",
    "href": "Slides/slides_06.html#the-sampling-distribution-of-coin-flips-1",
    "title": "Inference",
    "section": "The sampling distribution of coin flips",
    "text": "The sampling distribution of coin flips\n\n\n\n\nThe samples are centered around the expected proportion of .5 heads\n\n\n\n\nMore extreme errors are less common than small ones\n\n\n\n\nThe results are symmetric: there are about as many high values as low ones.\n\n\n\n\nError = Sample Mean - Population Mean, so the distribution of errors has this same shape, but its centered around zero."
  },
  {
    "objectID": "Slides/slides_06.html#the-sampling-distribution-of-coin-flips-2",
    "href": "Slides/slides_06.html#the-sampling-distribution-of-coin-flips-2",
    "title": "Inference",
    "section": "The sampling distribution of coin flips",
    "text": "The sampling distribution of coin flips\nCoin flips technically follow a binomial distribution but our sampling distribution looks a lot like a normal ‚Äúbell-curve‚Äù centered on .5"
  },
  {
    "objectID": "Slides/slides_06.html#sampling-distributions-of-sample-means",
    "href": "Slides/slides_06.html#sampling-distributions-of-sample-means",
    "title": "Inference",
    "section": "Sampling distributions of sample means",
    "text": "Sampling distributions of sample means\nIn fact, for a sufficient sample size, sampling distributions of sample means will always end up looking like this regardless of the actual population distribution."
  },
  {
    "objectID": "Slides/slides_06.html#the-normal-distribution",
    "href": "Slides/slides_06.html#the-normal-distribution",
    "title": "Inference",
    "section": "The normal distribution",
    "text": "The normal distribution\nWe know a lot about bell curves. If we have mean \\(\\mu\\) and a standard deviation \\(\\sigma\\), we can easily find how much data we expect to fall anywhere within this shape using the probability density function.\n\n\\[f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\n  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)\\]\n\n\n(Maybe not the kind of thing you want to calculate in your head, but pretty easy for a computer)"
  },
  {
    "objectID": "Slides/slides_06.html#the-normal-distribution-1",
    "href": "Slides/slides_06.html#the-normal-distribution-1",
    "title": "Inference",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nmu&lt;-0\nsigma&lt;-1\n\ncurve((1 / (sqrt(2*pi) * sigma)) * exp(-(x - mu)^2 / (2 * sigma^2)), from=-3, to=3,\n      xlab = '',\n      main = 'PDF of a normal with mean = 0 and sigma = 1'\n      )"
  },
  {
    "objectID": "Slides/slides_06.html#the-normal-distribution-2",
    "href": "Slides/slides_06.html#the-normal-distribution-2",
    "title": "Inference",
    "section": "The normal distribution",
    "text": "The normal distribution\nThe mean (\\(\\mu\\)) and standard deviation \\(\\sigma\\) will depend on the data, but we can always:\n\n\nMean center: subtract the mean \\(\\mu\\) from each observation so that the new mean is zero.\n\n\n\n\nStandardize: divide each observation by the standard deviation of the sampling distribution (\\(\\sigma\\)), so the new standard deviation is 1\n\n\n\nWe‚Äôll call this new number the ‚ÄúZ-score‚Äù:\n\\[\n\\text{Z score} = \\frac{\\text{Deviation from the mean}}{\\text{Standard Deviation}}\n\\]"
  },
  {
    "objectID": "Slides/slides_06.html#the-standard-normal-distribution",
    "href": "Slides/slides_06.html#the-standard-normal-distribution",
    "title": "Inference",
    "section": "The Standard Normal Distribution",
    "text": "The Standard Normal Distribution"
  },
  {
    "objectID": "Slides/slides_06.html#the-central-limit-theorem-1",
    "href": "Slides/slides_06.html#the-central-limit-theorem-1",
    "title": "Inference",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\nAs the number of repeated samples approaches infinity, the sampling distribution of the mean will converge toward a normal distribution centered on the population mean.\n\n\n\n\n\nThis means that:\n\n\nThe sampling errors will also have a normal distribution centered on zero.\n\n\n\n\nSampling errors/means are normally distributed even if the population is non-normal.\n\n\n\n\nWe can calculate the proportion of data that falls under different parts of the curve, provided we know \\(\\mu\\) and \\(\\sigma\\)"
  },
  {
    "objectID": "Slides/slides_06.html#using-the-clt",
    "href": "Slides/slides_06.html#using-the-clt",
    "title": "Inference",
    "section": "Using the CLT",
    "text": "Using the CLT\nWe don‚Äôt need to take infinite samples to make use of this! We can draw a sample and assume that it comes from a distribution with this shape:"
  },
  {
    "objectID": "Slides/slides_06.html#using-the-clt-1",
    "href": "Slides/slides_06.html#using-the-clt-1",
    "title": "Inference",
    "section": "Using the CLT",
    "text": "Using the CLT\n\\[f(x) = \\frac{1}{\\color{red}{\\sigma}\\sqrt{2\\pi}}\n  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\color{red}{\\mu}}{\\color{red}{\\sigma}}\\right)^{\\!2}\\,\\right)\\]\nRemember: we need to know \\(\\mu\\) and \\(\\sigma\\)\n\n\nWe don‚Äôt know our population mean \\(\\mu\\), but we do know that the mean sampling error is zero, so we can just use 0 our expected mean error.\nHowever, we still need to know the standard deviation \\(\\sigma\\)\n\nHere, we‚Äôre looking for the standard deviation of the sampling errors. We‚Äôll call this value our standard error or SE for short.\nFinding this is a challenge, but we can make some simple assumptions here to get a ‚Äúworst case scenario‚Äù for a survey"
  },
  {
    "objectID": "Slides/slides_06.html#the-standard-error",
    "href": "Slides/slides_06.html#the-standard-error",
    "title": "Inference",
    "section": "The standard error",
    "text": "The standard error\nRemember that more observations = more certainty. So we expect that the standard error will decrease when taking larger samples.\n\n\n\n\n\n\n\n\n\n\n\nWe actually know how much the SE shrinks for each observation:\n\n\\[\n\\text{Standard error (SE)} = \\frac{\\sigma}{\\sqrt{n}}\n\\]"
  },
  {
    "objectID": "Slides/slides_06.html#the-standard-error-of-a-proportion",
    "href": "Slides/slides_06.html#the-standard-error-of-a-proportion",
    "title": "Inference",
    "section": "The standard error of a proportion",
    "text": "The standard error of a proportion\n\n\\[\n\\text{Standard error (SE)} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\n\n\nWe don‚Äôt know \\(\\sigma\\), but surveys are usually reporting a proportion or percentage of people giving a particular response. The standard error of a proportion actually depends on the proportion itself:\n\n\\[\n\\text{Standard Error of a proportion} = \\frac{\\sqrt{p\\times(1-p)}}{\\sqrt{n}} = \\sqrt{\\frac{p\\times(1-p)}{n}}\n\\]\n\n\\[\np = \\text{the proportion}\n\\]"
  },
  {
    "objectID": "Slides/slides_06.html#the-standard-error-of-a-proportion-1",
    "href": "Slides/slides_06.html#the-standard-error-of-a-proportion-1",
    "title": "Inference",
    "section": "The standard error of a proportion",
    "text": "The standard error of a proportion\n\n\nNote that this part of the formula is at its maximum when p = .5 (i.e.¬†when there‚Äôs a 50/50 split on a yes/no question)\n\n\\[\n\\text{Standard Error of a proportion} = \\sqrt{\\frac{\\color{red}{p\\times(1-p)}}{n}}\n\\]\n\n\nSo, if we know our sample size, we can calculate the worst case scenario for the standard error where \\(p = .5\\)"
  },
  {
    "objectID": "Slides/slides_06.html#back-to-that-margin",
    "href": "Slides/slides_06.html#back-to-that-margin",
    "title": "Inference",
    "section": "Back to that margin",
    "text": "Back to that margin\n\n\n\nWe know our sample size is 2,091\n\n\n\nWe know that the biggest SE possible is when \\(p = .5\\), \\(\\sqrt{\\frac{.5(1-.5)}{n}}\\), so the worst case scenario is \\(\\sqrt{\\frac{.5(1-.5)}{2,091}} \\approx 0.0109\\)\n\n\n\n\nWe also know that the errors are normally distributed and centered around 0\n\n\n\nWe have all the ingredients to we need to apply the CLT here!\n\n\n\n\n\nfrom https://criticalissues.umd.edu/feature/new-study-change-us-public-attitudes-towards-jews-and-muslims-2022-2024"
  },
  {
    "objectID": "Slides/slides_06.html#the-margin-of-error",
    "href": "Slides/slides_06.html#the-margin-of-error",
    "title": "Inference",
    "section": "The Margin of error",
    "text": "The Margin of error\nRemember we want a 95% confidence level.\nWe already know that for this pdf, 95% of the errors will fall with in approximately \\(\\pm 2 \\times Z\\) of 0 (technically closer to 1.95994‚Ä¶)"
  },
  {
    "objectID": "Slides/slides_06.html#the-margin-of-error-1",
    "href": "Slides/slides_06.html#the-margin-of-error-1",
    "title": "Inference",
    "section": "The Margin of error",
    "text": "The Margin of error\n\n\n\\[\n\\text{Standard Error of a proportion} = \\sqrt{\\frac{p\\times(1-p)}{n}}\n\\]\n\\[\n\\text{SE for this sample at (p=0.5)} = \\sqrt{\\frac{.5(1-.5)}{2,091}} \\approx 0.0109\n\\]\nSo now we just need:\n\\[\n\\text{standard error} \\times \\text{Z-score for a 95% confidence level} =\n\\]\n\\[\n.0109 \\times 1.96 \\approx 0.0214 = 2.14\\%\n\\]\n\n\n\n\n\nfrom https://criticalissues.umd.edu/feature/new-study-change-us-public-attitudes-towards-jews-and-muslims-2022-2024"
  },
  {
    "objectID": "Slides/slides_06.html#the-margin-of-error-2",
    "href": "Slides/slides_06.html#the-margin-of-error-2",
    "title": "Inference",
    "section": "The Margin of error",
    "text": "The Margin of error\nSo what is the margin of error on a poll?\nIts a 95% confidence interval for a worst case scenario where there‚Äôs a 50/50 split on a question with two response categories."
  },
  {
    "objectID": "Slides/slides_06.html#the-central-limit-theorem-2",
    "href": "Slides/slides_06.html#the-central-limit-theorem-2",
    "title": "Inference",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nWhen I take a decent-sized random sample from the population:\n\n\nI know the sample mean (\\(\\bar{x}\\)) is drawn from a normal distribution.\nI know the mean of this sampling distribution is equal to the population mean.\nI know the standard deviation of this sampling distribution (a.ka. the standard error) is equal to \\(\\frac{\\sigma}{\\sqrt{n}}\\)\n\nSo: I know that 95% of my sample averages will be within \\(\\approx 1.96\\) standard errors of the correct answer (and any number of other probabilities based on the normal curve)"
  },
  {
    "objectID": "Slides/slides_06.html#calculating-a-95-confidence-interval",
    "href": "Slides/slides_06.html#calculating-a-95-confidence-interval",
    "title": "Inference",
    "section": "Calculating a 95% confidence interval",
    "text": "Calculating a 95% confidence interval\n\\[\n\\text{lower 95% confidence boundary} = \\bar{x} - 1.96  \\text{ standard errors}\n\\]\n\\[ \\text{upper 95% confidence boundary} = \\bar{x} + 1.96  \\text{ standard errors} \\]\n\nSometimes we‚Äôll just round this to ‚Äú2‚Äù because its usually good enough."
  },
  {
    "objectID": "Weeks/Week 01/Week-01.html",
    "href": "Weeks/Week 01/Week-01.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to GVPT 201! I hope everyone enjoyed the snow day. This week, we‚Äôre talking about the process of turning complex concepts into something measurable, and what can go wrong in the process.",
    "crumbs": [
      "Weeks",
      "Week 1"
    ]
  },
  {
    "objectID": "Weeks/Week 01/Week-01.html#lecture-slides",
    "href": "Weeks/Week 01/Week-01.html#lecture-slides",
    "title": "Week 1",
    "section": "Lecture slides",
    "text": "Lecture slides\n\nIntroductionsLecture 1\n\n\n\n\n\n\n\n\nClick here to view full screen. You can use your keypad to navigate the slides.\n\n\n\n\n\n\n&lt;a href=\"/Slides/slides_01.html\"&gt;&lt;/a&gt;\n\n\n\nClick here to view full screen. You can use your keypad to navigate the slides.",
    "crumbs": [
      "Weeks",
      "Week 1"
    ]
  },
  {
    "objectID": "Weeks/Week 01/Week-01.html#to-do",
    "href": "Weeks/Week 01/Week-01.html#to-do",
    "title": "Week 1",
    "section": "To-Do",
    "text": "To-Do\n\nRead chapter 1 of the textbook.\nInstall R and R-Studio by Friday so you‚Äôre ready for discussion sections.\nBe sure you‚Äôre checking the ELMS page for critical information.",
    "crumbs": [
      "Weeks",
      "Week 1"
    ]
  },
  {
    "objectID": "Weeks/Week 02/Week-02.html",
    "href": "Weeks/Week 02/Week-02.html",
    "title": "Week 2",
    "section": "",
    "text": "This week we‚Äôre looking at ways to describe, measure, and visualize central tendency and variation in data.",
    "crumbs": [
      "Weeks",
      "Week 2"
    ]
  },
  {
    "objectID": "Weeks/Week 02/Week-02.html#lecture-slides",
    "href": "Weeks/Week 02/Week-02.html#lecture-slides",
    "title": "Week 2",
    "section": "Lecture slides",
    "text": "Lecture slides\n\nMondayWednesday\n\n\n\n\n\n\n\nClick here to view full screen. You can use your keypad to navigate the slides.\n\n\n\n\n\n\n\nClick here to view full screen. You can use your keypad to navigate the slides.",
    "crumbs": [
      "Weeks",
      "Week 2"
    ]
  },
  {
    "objectID": "Weeks/Week 02/Week-02.html#to-do",
    "href": "Weeks/Week 02/Week-02.html#to-do",
    "title": "Week 2",
    "section": "To-Do",
    "text": "To-Do\n\nRead chapter 2 of the textbook\nWorkbook homework 1 is due on Thursday.\nSubmit a survey question by Friday.",
    "crumbs": [
      "Weeks",
      "Week 2"
    ]
  },
  {
    "objectID": "faqs.html",
    "href": "faqs.html",
    "title": "FAQs",
    "section": "",
    "text": "This is a running list of questions (primarily R-related) that have come up a lot over the semester. If you‚Äôre here, you might also want to check out the page on basic troubleshooting in R.",
    "crumbs": [
      "Additional Resources",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#how-do-i-access-the-help-file-for-a-function",
    "href": "faqs.html#how-do-i-access-the-help-file-for-a-function",
    "title": "FAQs",
    "section": "How do I access the help file for a function?",
    "text": "How do I access the help file for a function?\nYou can access the help file for a function by typing help(function name) into the console:\n\nhelp(c) # get the help file for the \"c\" function\n\nIf the function is associated with the RCPA3 package, it should have some reasonably detailed information about how each function works, but it will also have links to some short YouTube videos that illustrate how to use them, so consider giving those a watch if you‚Äôre stuck.",
    "crumbs": [
      "Additional Resources",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#when-do-i-need-to-use-weights",
    "href": "faqs.html#when-do-i-need-to-use-weights",
    "title": "FAQs",
    "section": "When do I need to use weights?",
    "text": "When do I need to use weights?\nYou‚Äôll typically use a weighting variable when you‚Äôre working with survey data. In this course, the nes data set will include a weight variable (wt), but there aren‚Äôt any weights for the world or states data sets.\nWeighting is used to make samples more closely resemble a target population. For instance, the NES has slightly more women respondents than you would expect from a true random sample from the general population so including the weighting variable makes the responses from men count more and the responses from women count slightly less.\n\n\n\n\n\n\ngender\nunweighted\nweighted\n\n\n\n\n1. Male\n3763 (46%)\n3964 (48%)\n\n\n2. Female\n4450 (54%)\n4262 (52%)\n\n\n\n\n\n\n\n\nThis concern isn‚Äôt really relevant for the world and states data sets because these aren‚Äôt samples: the states data set has data on the entire population of U.S. states, and the world data set has data on (more or less) all the countries.",
    "crumbs": [
      "Additional Resources",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#what-does-the-symbol-mean-as-in-worldccode",
    "href": "faqs.html#what-does-the-symbol-mean-as-in-worldccode",
    "title": "FAQs",
    "section": "What does the $ symbol mean (as in world$ccode)?",
    "text": "What does the $ symbol mean (as in world$ccode)?\nThe $ notation is one way that we can access a specific column of a dataframe in R. For instance, here‚Äôs a portion of the states data set:\n\n\n\n\nstateattend.pctabortlaws\n\nAlabama528\n\nAlaska228\n\nArizona2911\n\nArkansas5010\n\nCalifornia335\n\n\n\n\nIf I want to access the attend.pct variable, I can just type:\n\nstates$attend.pct\n\n [1] 52 22 29 50 33 29 30 35 35 45 35 45 39 44 40 48 47 53 23 37 30 38 38 60 43\n[26] 31 47 30 23 36 34 32 49 42 36 50 32 39 30 54 42 52 47 57 23 41 33 43 33 31\nattr(,\"label\")\n[1] \"% freq attend relig serv (Pew)\"\n\n\nTyping out a data set name and a dollar sign can get a little tedious, so many R functions will allow you to use an optional data argument that will allow you to just list column names without adding the name of the data set first. For example: these two commands will generate the exact same result, the only difference is that adding data=states saves me from having to write states$... over and over:\n\n# with the data = argument\ncompmeansC(dv = attend.pct, iv = region, data=states)\n\n# without the data = argument\ncompmeansC(dv= states$attend.pct, iv = states$region)",
    "crumbs": [
      "Additional Resources",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#why-am-i-getting-error-object-__-not-found",
    "href": "faqs.html#why-am-i-getting-error-object-__-not-found",
    "title": "FAQs",
    "section": "Why am I getting Error: object __ not found?",
    "text": "Why am I getting Error: object __ not found?\nOkay, there could be lots of reasons for this error message, but the most common cause is that you‚Äôve either:\n\nMis-spelled a variable name.\nReferenced a variable without specifying the data set where that variable is stored.\nReferenced a variable that is not yet available in R.\n\nWhen you reference a variable in R, it searches for that variable in the current environment, and it returns an error message when it can‚Äôt find it. So the code below returns and error because x hasn‚Äôt been defined yet:\n\nx\n\nError: object 'x' not found\n\n\nTo access xI first need to create it by assigning a value (in this case, some text in quotation marks) to that name. This works just fine:\n\nx&lt;-\"I am a variable\"\n\nx\n\n[1] \"I am a variable\"\n\n\nThe other place this comes up is when you try to access a column from a data set without specifying the data set where that variable exists. For instance, ‚Äúage‚Äù is a column in the nes data, but just typing ‚Äúage‚Äù doesn‚Äôt work because R doesn‚Äôt know where to look:\n\nmean(age, na.rm=T)\n\nError: object 'age' not found\n\n\nUsing the dataset$varname syntax solves this problem:\n\nmean(nes$age, na.rm=T)\n\n[1] 51.58522",
    "crumbs": [
      "Additional Resources",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#what-are-factor-variables",
    "href": "faqs.html#what-are-factor-variables",
    "title": "FAQs",
    "section": "What are factor variables?",
    "text": "What are factor variables?\nA factor variable is R‚Äôs default data type for storing categorical data. Technically, a factor is actually just a bunch of integers with a special levels attribute that specifies the labels that those integers correspond to:\n\nexample_factor &lt;- factor(c(1,1,2,2,3,4), labels = c('A', 'B', 'C', 'D'))\nexample_factor\n\n[1] A A B B C D\nLevels: A B C D\n\n\nR can also just store regular text data, but factors have some distinct advantages when working with certain data sources. The most important is that they allow us to control the ordering of tables and graphs. For example, if I make a table with a character variable, R prints the elements in alphabetical order:\n\nstring_vector &lt;- c(\"Disagree\", \"Neither disagree nor agree\", \"Agree\")\ntable(string_vector)\n\nstring_vector\n                     Agree                   Disagree \n                         1                          1 \nNeither disagree nor agree \n                         1 \n\n\nBut alphabetizing this doesn‚Äôt make sense because the variable has a clear ordering from disagree to agree. The ‚Äúlevels‚Äù attribute on a factor allows me to preserve that ordering:\n\nfactor_vector &lt;- factor(string_vector, \n                        # list of the levels the order I want them to appear: \n                        levels =c(\"Disagree\", \"Neither disagree nor agree\", \"Agree\"))\n\ntable(factor_vector)\n\nfactor_vector\n                  Disagree Neither disagree nor agree \n                         1                          1 \n                     Agree \n                         1 \n\n\nSince each level of a factor also has a numeric value, we can also do things like calculate the median value of an ordered variable:\n\nmedian(as.numeric(factor_vector))\n\n[1] 2",
    "crumbs": [
      "Additional Resources",
      "FAQs"
    ]
  },
  {
    "objectID": "lecture_slides.html",
    "href": "lecture_slides.html",
    "title": "Slides",
    "section": "",
    "text": "Slides from previous lectures are in this section. (You‚Äôll also see placeholders for future lecture slides. I haven‚Äôt made these yet!)"
  },
  {
    "objectID": "outfile.html",
    "href": "outfile.html",
    "title": "Schedule",
    "section": "",
    "text": "Note that this schedule is subject to change. Be sure to check ELMS for the most up-to-date information on due dates.\n\nGVPT 201 Spring 2026 Schedule\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nTextbook\nHomework\nSlides\n\n\n\n\nWeek 1\nJan 26\nConcepts and measurement\nChapter 1\nHomework 1 due Feb 05Survey question due Feb 06\nIntro\n\n\n\nJan 28\n\n\n\nLecture 1\n\n\nWeek 2\nFeb 02\nDescription\nChapter 2\nHomework 2 due Feb 12\nLecture 2\n\n\n\nFeb 04\n\n\n\nLecture 3\n\n\nWeek 3\nFeb 09\nTransforming variables\nChapter 3\nHomework 3 due Feb 19\nLecture 4\n\n\n\nFeb 11\n\n\n\nLecture 5\n\n\nWeek 4\nFeb 16\nExplanations and hypotheses\nChapter 4\nHomework 4 due Feb 26Survey distribution due Feb 27\nLecture 6\n\n\n\nFeb 18\n\n\n\nLecture 7\n\n\nWeek 5\nFeb 23\nGraphing and describing patterns\nChapter 5\nHomework 5 due Mar 05\nLecture 8\n\n\n\nFeb 25\n\n\n\nLecture 9\n\n\nWeek 6\nMar 02\nResearch and causation\nChapter 6\nHomework 6 due Mar 12\nLecture 10\n\n\n\nMar 04\n\n\n\nLecture 11\n\n\nWeek 7\nMar 09\nControlled comparisons\nChapter 7\n\nLecture 12\n\n\n\nMar 11\n\n\nMidterm I\n\n\n\nWeek 8\nMar 16\n\nSpring Break\n\n\n\n\n\nMar 18\n\nSpring Break\n\n\n\n\nWeek 9\nMar 23\nInference\nChapter 8\nHomework 7 due Mar 26Survey practice I due Mar 27\nLecture 13\n\n\n\nMar 25\n\n\n\nLecture 14\n\n\nWeek 10\nMar 30\nHypothesis testing\nChapter 9\nHomework 8 due Apr 09\nLecture 15\n\n\n\nApr 01\n\n\n\nLecture 16\n\n\nWeek 11\nApr 06\nChi-2 and measures of variance/Correlation and Regression\nChapter 10 and Chapter 11\nHomework 9 due Apr 16\nLecture 17\n\n\n\nApr 08\n\n\n\nLecture 18\n\n\nWeek 12\nApr 13\nMultiple Regression\nChapter 12\nHomework 10 due Apr 23\nLecture 19\n\n\n\nApr 15\n\n\n\nLecture 20\n\n\nWeek 13\nApr 20\nAnalyzing residuals\nChapter 13\nSurvey practice II due May 01\nLecture 21\n\n\n\nApr 22\n\n\n\nLecture 22\n\n\nWeek 14\nApr 27\nLogistic regression\nChapter 14\nOptional Homework 11 due May 07\nLecture 23\n\n\n\nApr 29\n\n\n\nLecture 24\n\n\nWeek 15\nMay 04\nWrap up and review\nChapter 15\nFinal projectduring final exam period\nLecture 25\n\n\n\nMay 06\nMidterm"
  },
  {
    "objectID": "schedule_original.html",
    "href": "schedule_original.html",
    "title": "Schedule",
    "section": "",
    "text": "Note that this schedule is subject to change. Be sure to check ELMS for the most up-to-date information on due dates.\n\nGVPT 201 Spring 2026 Schedule\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nTextbook\nHomework\nSlides\n\n\n\n\nWeek 1\nJan 26\nConcepts and measurement\nChapter 1\nHomework 1 due Feb 05Survey question due Feb 06\nIntro\n\n\n\nJan 28\n\n\n\nLecture 1\n\n\nWeek 2\nFeb 02\nDescription\nChapter 2\nHomework 2 due Feb 12\nLecture 2\n\n\n\nFeb 04\n\n\n\nLecture 3\n\n\nWeek 3\nFeb 09\nTransforming variables\nChapter 3\nHomework 3 due Feb 19\nLecture 4\n\n\n\nFeb 11\n\n\n\nLecture 5\n\n\nWeek 4\nFeb 16\nExplanations and hypotheses\nChapter 4\nHomework 4 due Feb 26Survey distribution due Feb 27\nLecture 6\n\n\n\nFeb 18\n\n\n\nLecture 7\n\n\nWeek 5\nFeb 23\nGraphing and describing patterns\nChapter 5\nHomework 5 due Mar 05\nLecture 8\n\n\n\nFeb 25\n\n\n\nLecture 9\n\n\nWeek 6\nMar 02\nResearch and causation\nChapter 6\nHomework 6 due Mar 12\nLecture 10\n\n\n\nMar 04\n\n\n\nLecture 11\n\n\nWeek 7\nMar 09\nControlled comparisons\nChapter 7\n\nLecture 12\n\n\n\nMar 11\n\n\nMidterm I\n\n\n\nWeek 8\nMar 16\n\nSpring Break\n\n\n\n\n\nMar 18\n\nSpring Break\n\n\n\n\nWeek 9\nMar 23\nInference\nChapter 8\nHomework 7 due Mar 26Survey practice I due Mar 27\nLecture 13\n\n\n\nMar 25\n\n\n\nLecture 14\n\n\nWeek 10\nMar 30\nHypothesis testing\nChapter 9\nHomework 8 due Apr 09\nLecture 15\n\n\n\nApr 01\n\n\n\nLecture 16\n\n\nWeek 11\nApr 06\nChi-2 and measures of variance/Correlation and Regression\nChapter 10 and Chapter 11\nHomework 9 due Apr 16\nLecture 17\n\n\n\nApr 08\n\n\n\nLecture 18\n\n\nWeek 12\nApr 13\nMultiple Regression\nChapter 12\nHomework 10 due Apr 23\nLecture 19\n\n\n\nApr 15\n\n\n\nLecture 20\n\n\nWeek 13\nApr 20\nAnalyzing residuals\nChapter 13\nSurvey practice II due May 01\nLecture 21\n\n\n\nApr 22\n\n\n\nLecture 22\n\n\nWeek 14\nApr 27\nLogistic regression\nChapter 14\nOptional Homework 11 due May 07\nLecture 23\n\n\n\nApr 29\n\n\n\nLecture 24\n\n\nWeek 15\nMay 04\nWrap up and review\nChapter 15\nFinal projectduring final exam period\nLecture 25\n\n\n\nMay 06\nMidterm"
  },
  {
    "objectID": "tips.html",
    "href": "tips.html",
    "title": "tips",
    "section": "",
    "text": "(I‚Äôll be adding stuff to this section as I encounter it)\n\n\nYou‚Äôll typically use a weighting variable when you‚Äôre working with survey data. In this course, the nes data set will include a weight variable (wt), but there aren‚Äôt any weights for the world or states data sets.\nWeighting is used to make samples more closely resemble a target population. For instance, the NES has slightly more women respondents than you would expect from a true random sample from the general population so including the weighting variable makes the responses from men count more and the responses from women count slightly less.\n\n\n\n\n\n\ngender\nunweighted\nweighted\n\n\n\n\n1. Male\n3763 (46%)\n3964 (48%)\n\n\n2. Female\n4450 (54%)\n4262 (52%)\n\n\n\n\n\n\n\n\nThis concern isn‚Äôt really relevant for the world and states data sets because these aren‚Äôt samples: the states data set has data on the entire population of U.S. states, and the world data set has data on (more or less) all the countries.\n\n\n\nThey svyglm function is used to run a weighted regression, but the final project data doesn‚Äôt have any weights associated with it, so you don‚Äôt need any of the svy commands to do your analysis. Keep in mind, however, that these data are still not representative of the general population, so you should acknowledge that this is a non-random sample when you discuss your results.\n\n\n\nYou are not obligated to find statistically significant results. As long as you make a reasonable argument for why your hypothesis is worth testing, this is completely fine. If you do find that your hypothesis isn‚Äôt supported, you still need to interpret the coefficients, plot the results etc. you just need to say that you‚Äôve failed to reject the null. In the concluding section of the paper, you would also want to talk about why you think your hypothesis wasn‚Äôt supported. A few plausible reasons are: you‚Äôre wrong, there‚Äôs not enough data, there‚Äôs uncontrolled confounding, or the sample is biased. You don‚Äôt need to give a definitive explanation, just show you‚Äôre thinking about your results and that you understand what it means to reject or not reject the null hypothesis.\n(If you think there‚Äôs uncontrolled confounding and it comes from a variable that already exists in the data, you might as well test it! But its entirely possible that there‚Äôs some other confounding variable that wasn‚Äôt included in the data, in which case its fine to say ‚ÄúI suspect this matters, but I can‚Äôt test it‚Äù)\n\n\n\nBefore submitting your R-code, its a good idea to double-check and make sure everything runs properly. The best way to do this is: restart R, press little broom icon in the environment pane to make sure you‚Äôve cleared all of the your data out, and then run your script one line at a time and make sure that you don‚Äôt see any errors. If you‚Äôre not able to reproduce the results in your paper, then you may need to check to make sure you have everything in the right order.\n\n\n\nThe $ notation is one way that we can access a specific column of a dataframe in R. For instance, here‚Äôs a portion of the states data set:\n\n\n\n\nstateattend.pctabortlaws\n\nAlabama528\n\nAlaska228\n\nArizona2911\n\nArkansas5010\n\nCalifornia335\n\n\n\n\nIf I want to access the attend.pct variable, I can just type:\n\nstates$attend.pct\n\nTyping out a data set name and a dollar sign can get a little tedious, so many R functions will allow you to use an optional data argument that will allow you to be a little more concise. So these two commands will generate the exact same result, the only difference is that adding data=states saves me from having to write states$... over and over:\n\n# with the data = argument\ncompmeansC(dv = attend.pct, iv = region, data=states)\n\n===========================================================================\n                         Mean Comparison Analysis\n===========================================================================\n\n\nTable: Mean Values of attend.pct by region\n\n              Mean    N   St. Dev.\n----------  ------  ---  ---------\nNortheast    29.56    9       5.77\nMidwest      40.83   12       4.39\nSouth        46.88   16       7.16\nWest         33.92   13       8.59\nTotal        38.94   50       9.37\n\n\n\n\n\n\n\n\n# without the data = argument\ncompmeansC(dv= states$attend.pct, iv = states$region)\n\n===========================================================================\n                         Mean Comparison Analysis\n===========================================================================\n\n\nTable: Mean Values of states$attend.pct by states$region\n\n              Mean    N   St. Dev.\n----------  ------  ---  ---------\nNortheast    29.56    9       5.77\nMidwest      40.83   12       4.39\nSouth        46.88   16       7.16\nWest         33.92   13       8.59\nTotal        38.94   50       9.37\n\n\n\n\n\n\n\n\n\n\n\n\nna.rm=T is an optional command that will allow us to calculate summary statistics for data that has missing values. When an observation has some missing values, R will use a special NA value as a placeholder for that cell. This is a problem when we want to calculate a summary statistic because NA doesn‚Äôt have any mathematical meaning: its just non-existent data.\nBy default, taking the mean, median, sum etc. from a vector with any NA values will just return NA:\n\nmean(world$gdp.growth)\n\n[1] NA\n\n\nSo, adding na.rm=T will just tell R to ignore any NA values and perform the calculation only on the valid observations:\n\nmean(world$gdp.growth, na.rm=T)\n\n[1] 2.982785"
  },
  {
    "objectID": "tips.html#when-do-i-need-to-use-weights",
    "href": "tips.html#when-do-i-need-to-use-weights",
    "title": "tips",
    "section": "",
    "text": "You‚Äôll typically use a weighting variable when you‚Äôre working with survey data. In this course, the nes data set will include a weight variable (wt), but there aren‚Äôt any weights for the world or states data sets.\nWeighting is used to make samples more closely resemble a target population. For instance, the NES has slightly more women respondents than you would expect from a true random sample from the general population so including the weighting variable makes the responses from men count more and the responses from women count slightly less.\n\n\n\n\n\n\ngender\nunweighted\nweighted\n\n\n\n\n1. Male\n3763 (46%)\n3964 (48%)\n\n\n2. Female\n4450 (54%)\n4262 (52%)\n\n\n\n\n\n\n\n\nThis concern isn‚Äôt really relevant for the world and states data sets because these aren‚Äôt samples: the states data set has data on the entire population of U.S. states, and the world data set has data on (more or less) all the countries."
  },
  {
    "objectID": "tips.html#do-i-need-to-use-svyglm",
    "href": "tips.html#do-i-need-to-use-svyglm",
    "title": "tips",
    "section": "",
    "text": "They svyglm function is used to run a weighted regression, but the final project data doesn‚Äôt have any weights associated with it, so you don‚Äôt need any of the svy commands to do your analysis. Keep in mind, however, that these data are still not representative of the general population, so you should acknowledge that this is a non-random sample when you discuss your results."
  },
  {
    "objectID": "tips.html#is-it-okay-if-my-results-are-not-significant",
    "href": "tips.html#is-it-okay-if-my-results-are-not-significant",
    "title": "tips",
    "section": "",
    "text": "You are not obligated to find statistically significant results. As long as you make a reasonable argument for why your hypothesis is worth testing, this is completely fine. If you do find that your hypothesis isn‚Äôt supported, you still need to interpret the coefficients, plot the results etc. you just need to say that you‚Äôve failed to reject the null. In the concluding section of the paper, you would also want to talk about why you think your hypothesis wasn‚Äôt supported. A few plausible reasons are: you‚Äôre wrong, there‚Äôs not enough data, there‚Äôs uncontrolled confounding, or the sample is biased. You don‚Äôt need to give a definitive explanation, just show you‚Äôre thinking about your results and that you understand what it means to reject or not reject the null hypothesis.\n(If you think there‚Äôs uncontrolled confounding and it comes from a variable that already exists in the data, you might as well test it! But its entirely possible that there‚Äôs some other confounding variable that wasn‚Äôt included in the data, in which case its fine to say ‚ÄúI suspect this matters, but I can‚Äôt test it‚Äù)"
  },
  {
    "objectID": "tips.html#how-can-i-make-sure-that-my-code-is-replicable",
    "href": "tips.html#how-can-i-make-sure-that-my-code-is-replicable",
    "title": "tips",
    "section": "",
    "text": "Before submitting your R-code, its a good idea to double-check and make sure everything runs properly. The best way to do this is: restart R, press little broom icon in the environment pane to make sure you‚Äôve cleared all of the your data out, and then run your script one line at a time and make sure that you don‚Äôt see any errors. If you‚Äôre not able to reproduce the results in your paper, then you may need to check to make sure you have everything in the right order."
  },
  {
    "objectID": "tips.html#what-does-the-symbol-mean-as-inworldccode",
    "href": "tips.html#what-does-the-symbol-mean-as-inworldccode",
    "title": "tips",
    "section": "",
    "text": "The $ notation is one way that we can access a specific column of a dataframe in R. For instance, here‚Äôs a portion of the states data set:\n\n\n\n\nstateattend.pctabortlaws\n\nAlabama528\n\nAlaska228\n\nArizona2911\n\nArkansas5010\n\nCalifornia335\n\n\n\n\nIf I want to access the attend.pct variable, I can just type:\n\nstates$attend.pct\n\nTyping out a data set name and a dollar sign can get a little tedious, so many R functions will allow you to use an optional data argument that will allow you to be a little more concise. So these two commands will generate the exact same result, the only difference is that adding data=states saves me from having to write states$... over and over:\n\n# with the data = argument\ncompmeansC(dv = attend.pct, iv = region, data=states)\n\n===========================================================================\n                         Mean Comparison Analysis\n===========================================================================\n\n\nTable: Mean Values of attend.pct by region\n\n              Mean    N   St. Dev.\n----------  ------  ---  ---------\nNortheast    29.56    9       5.77\nMidwest      40.83   12       4.39\nSouth        46.88   16       7.16\nWest         33.92   13       8.59\nTotal        38.94   50       9.37\n\n\n\n\n\n\n\n\n# without the data = argument\ncompmeansC(dv= states$attend.pct, iv = states$region)\n\n===========================================================================\n                         Mean Comparison Analysis\n===========================================================================\n\n\nTable: Mean Values of states$attend.pct by states$region\n\n              Mean    N   St. Dev.\n----------  ------  ---  ---------\nNortheast    29.56    9       5.77\nMidwest      40.83   12       4.39\nSouth        46.88   16       7.16\nWest         33.92   13       8.59\nTotal        38.94   50       9.37"
  },
  {
    "objectID": "tips.html#what-does-na.rmt-mean",
    "href": "tips.html#what-does-na.rmt-mean",
    "title": "tips",
    "section": "",
    "text": "na.rm=T is an optional command that will allow us to calculate summary statistics for data that has missing values. When an observation has some missing values, R will use a special NA value as a placeholder for that cell. This is a problem when we want to calculate a summary statistic because NA doesn‚Äôt have any mathematical meaning: its just non-existent data.\nBy default, taking the mean, median, sum etc. from a vector with any NA values will just return NA:\n\nmean(world$gdp.growth)\n\n[1] NA\n\n\nSo, adding na.rm=T will just tell R to ignore any NA values and perform the calculation only on the valid observations:\n\nmean(world$gdp.growth, na.rm=T)\n\n[1] 2.982785"
  },
  {
    "objectID": "Slides/slides_01.html#measuring-reliability",
    "href": "Slides/slides_01.html#measuring-reliability",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Measuring reliability",
    "text": "Measuring reliability\n\nTest-Retest method: give the same test to the same group twice. Measure the correlation between answers."
  },
  {
    "objectID": "Slides/slides_01.html#measuring-reliability-1",
    "href": "Slides/slides_01.html#measuring-reliability-1",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Measuring reliability",
    "text": "Measuring reliability\n\nZaller, J., & Feldman, S. (1992). A simple theory of the survey response: Answering questions versus revealing preferences. American journal of political science, 579-616."
  },
  {
    "objectID": "Slides/slides_01.html#measuring-reliability-2",
    "href": "Slides/slides_01.html#measuring-reliability-2",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Measuring reliability",
    "text": "Measuring reliability\n\nSplit half: for a measurement using a multi-item scale, we can split results and use half the questions to predict the remaining half.\n\nIf the scale questions all measure the same ‚Äúthing‚Äù then you would expect the halves to resemble each other."
  },
  {
    "objectID": "Slides/slides_02-2.html#histogram",
    "href": "Slides/slides_02-2.html#histogram",
    "title": "Visualization",
    "section": "Histogram",
    "text": "Histogram\n\n\n\nUse: visualizing the distribution of interval variables.\nDivide data into equally sized ‚Äúbins‚Äù and count the number in each. The height of each bar indicates the number of values in that bin."
  },
  {
    "objectID": "Slides/slides_02-2.html#density-plot",
    "href": "Slides/slides_02-2.html#density-plot",
    "title": "Visualization",
    "section": "Density Plot",
    "text": "Density Plot\n\n\n\nUse: visualizing the distribution of interval variables\nSort of a ‚Äúsmoothed‚Äù version of the histogram. The area of the entire curve is one, and the height of the curve at a given point indicates how much of the data is in that region."
  },
  {
    "objectID": "Slides/slides_02-2.html#box-plot",
    "href": "Slides/slides_02-2.html#box-plot",
    "title": "Visualization",
    "section": "Box plot",
    "text": "Box plot\n\n\n\nUse: visualizing the distribution of interval variables.\nShows the ‚Äúfive number summary‚Äù (minimum, 25th percentile, median/mean, 75th percentile, maximum)\nEspecially useful for making comparisons across groups or describing multiple items with similar scales."
  },
  {
    "objectID": "Slides/slides_02-2.html#bar-plot",
    "href": "Slides/slides_02-2.html#bar-plot",
    "title": "Visualization",
    "section": "Bar plot",
    "text": "Bar plot\n\n\n\nUse: visualizing the distribution of categorical variables\nCount the frequency (or proportion) of observations in each group"
  },
  {
    "objectID": "Slides/slides_01.html#party-id-4",
    "href": "Slides/slides_01.html#party-id-4",
    "title": "Chapter 1: Concepts and definitions",
    "section": "Party ID",
    "text": "Party ID\n\nThe ANES method for measuring party ID is hardly the only option we have, but it has some nice features:\n\nIt‚Äôs relatively reliable and survey respondents understand it\nIt‚Äôs close to the conceptual definition of party ID as a sort of self-identity or group affinity.\nIt‚Äôs transparent and widely used\nIt limits the influence of social desirability bias by giving respondents lots of options\nIt‚Äôs linked to an observed behavior: vote choice"
  }
]